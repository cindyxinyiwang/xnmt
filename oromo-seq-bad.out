Singularity: Invoking an interactive shell within container...

[0m/opt/cudnn-8.0/lib64:/home/xinyiw1/software/dynet-repo/dynet/build/dynet/:/projects/tir1/cuda-8.0.27.1/lib64:/opt/cudnn-5.1/lib64:/opt/cuda-8.0/lib64:/opt/cuda-8.0/lib:/opt/cuda-8.0/lib64/:/home/xinyiw1/gcc-5.2.0/lib64:/home/xinyiw1/boost_1_65_1/lib:/home/xinyiw1/gcc-5.2.0/lib:/opt/cuda-8.0/lib64/:/home/xinyiw1/gcc-5.2.0/lib64:/home/xinyiw1/boost_1_65_1/lib:/home/xinyiw1/gcc-5.2.0/lib:/opt/cuda-8.0/lib64/:/home/xinyiw1/gcc-5.2.0/lib64:/home/xinyiw1/boost_1_65_1/lib:/home/xinyiw1/gcc-5.2.0/lib:/opt/cuda-8.0/lib64/:/home/xinyiw1/gcc-5.2.0/lib64:/home/xinyiw1/boost_1_65_1/lib:/home/xinyiw1/gcc-5.2.0/lib:/opt/openmpi/lib
[dynet] initializing CUDA
Request for 1 GPU ...
[dynet] Device Number: 0
[dynet]   Device name: GeForce GTX 1080 Ti
[dynet]   Memory Clock Rate (KHz): 5505000
[dynet]   Memory Bus Width (bits): 352
[dynet]   Peak Memory Bandwidth (GB/s): 484.44
[dynet]   Memory Free (GB): 11.5421/11.7151
[dynet]
[dynet] Device(s) selected: 0
[dynet] random seed: 358753678
[dynet] allocating memory: 10000MB
[dynet] memory allocation done.
=> Running oromo-seq
   > Preprocessing   
   > Training   
   initialized BilingualTrainingCorpus({'train_src': '/projects/tir2/users/xinyiw1/loreili/train.piece.src', 'dev_trg': '/projects/tir2/users/xinyiw1/loreili/dev.piece.trg', 'dev_ref_file': '/projects/tir2/users/xinyiw1/loreili/dev.clean.trg', 'dev_src': '/projects/tir2/users/xinyiw1/loreili/dev.piece.src', 'train_trg': '/projects/tir2/users/xinyiw1/loreili/train.piece.trg'})   
   initialized PlainTextReader({})   
   initialized PlainTextReader({})   
   initialized BilingualCorpusParser({'trg_reader': <xnmt.input.PlainTextReader object at 0x7f7351ea7bd0>, 'src_reader': <xnmt.input.PlainTextReader object at 0x7f7351ea7d90>})   
   /projects/tir2/users/xinyiw1/loreili/train.piece.src   
   /projects/tir2/users/xinyiw1/loreili/train.piece.trg   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.trg   
   initialized SimpleWordEmbedder({'vocab_size': 8074, 'yaml_context': <xnmt.model_context.ModelContext object at 0x7f7351ea7a50>})   
   initialized LSTMSeqTransducer({'layers': 1, 'yaml_context': <xnmt.model_context.ModelContext object at 0x7f7351ea7a50>})   
   initialized StandardAttender({'yaml_context': <xnmt.model_context.ModelContext object at 0x7f7351ea7a50>})   
   initialized SimpleWordEmbedder({'vocab_size': 8067, 'yaml_context': <xnmt.model_context.ModelContext object at 0x7f7351ea7a50>})   
   initialized CopyBridge({'yaml_context': <xnmt.model_context.ModelContext object at 0x7f7351ea7a50>, 'dec_layers': 1})   
   initialized MlpSoftmaxDecoder({'layers': 1, 'bridge': <xnmt.decoder.CopyBridge object at 0x7f734fa21190>, 'yaml_context': <xnmt.model_context.ModelContext object at 0x7f7351ea7a50>, 'mlp_hidden_dim': 512, 'vocab_size': 8067})   
   initialized DefaultTranslator({'src_embedder': <xnmt.embedder.SimpleWordEmbedder object at 0x7f734fa16f90>, 'decoder': <xnmt.decoder.MlpSoftmaxDecoder object at 0x7f734fa21150>, 'trg_embedder': <xnmt.embedder.SimpleWordEmbedder object at 0x7f734fa21110>, 'attender': <xnmt.attender.StandardAttender object at 0x7f734fa210d0>, 'encoder': <xnmt.lstm.LSTMSeqTransducer object at 0x7f734fa16fd0>})   
   initialized SrcBatcher({'batch_size': 32})   
   Epoch 0.0286: train_loss/word=4.500 (words=19424, words/sec=5930.98, time=0-00:00:03)   
   Epoch 0.0563: train_loss/word=4.235 (words=38240, words/sec=5868.39, time=0-00:00:06)   
   Epoch 0.0841: train_loss/word=4.060 (words=52096, words/sec=6173.21, time=0-00:00:08)   
   Epoch 0.1118: train_loss/word=3.884 (words=66624, words/sec=6171.17, time=0-00:00:11)   
   Epoch 0.1404: train_loss/word=3.845 (words=84256, words/sec=5905.70, time=0-00:00:14)   
   Epoch 0.1681: train_loss/word=3.791 (words=100736, words/sec=6016.59, time=0-00:00:16)   
   Epoch 0.1958: train_loss/word=3.750 (words=111200, words/sec=6107.01, time=0-00:00:18)   
   Epoch 0.2236: train_loss/word=3.642 (words=124320, words/sec=6435.72, time=0-00:00:20)   
   Epoch 0.2522: train_loss/word=3.578 (words=136448, words/sec=6304.42, time=0-00:00:22)   
   Epoch 0.2799: train_loss/word=3.612 (words=158624, words/sec=5793.55, time=0-00:00:26)   
   Epoch 0.3076: train_loss/word=3.584 (words=174336, words/sec=5799.18, time=0-00:00:29)   
   Epoch 0.3353: train_loss/word=3.553 (words=185760, words/sec=6191.08, time=0-00:00:30)   
   Epoch 0.3640: train_loss/word=3.533 (words=203040, words/sec=6079.90, time=0-00:00:33)   
   Epoch 0.3917: train_loss/word=3.504 (words=216960, words/sec=6110.59, time=0-00:00:35)   
   Epoch 0.4194: train_loss/word=3.472 (words=230432, words/sec=6081.87, time=0-00:00:38)   
   Epoch 0.4471: train_loss/word=3.451 (words=244320, words/sec=6093.85, time=0-00:00:40)   
   Epoch 0.4757: train_loss/word=3.438 (words=261600, words/sec=6024.92, time=0-00:00:43)   
   Epoch 0.5035: train_loss/word=3.415 (words=273600, words/sec=6211.09, time=0-00:00:45)   
   Epoch 0.5312: train_loss/word=3.410 (words=288608, words/sec=5922.26, time=0-00:00:47)   
   Epoch 0.5589: train_loss/word=3.389 (words=299392, words/sec=6182.20, time=0-00:00:49)   
   Epoch 0.5875: train_loss/word=3.374 (words=314720, words/sec=6003.03, time=0-00:00:52)   
   Epoch 0.6152: train_loss/word=3.370 (words=330432, words/sec=5929.03, time=0-00:00:54)   
   Epoch 0.6430: train_loss/word=3.361 (words=343104, words/sec=5559.13, time=0-00:00:57)   
   Epoch 0.6707: train_loss/word=3.340 (words=358848, words/sec=6193.41, time=0-00:00:59)   
   Epoch 0.6993: train_loss/word=3.322 (words=370528, words/sec=6192.54, time=0-00:01:01)   
   Epoch 0.7270: train_loss/word=3.307 (words=379456, words/sec=6105.44, time=0-00:01:02)   
   Epoch 0.7547: train_loss/word=3.305 (words=396160, words/sec=5738.53, time=0-00:01:05)   
   Epoch 0.7825: train_loss/word=3.309 (words=417344, words/sec=5784.90, time=0-00:01:09)   
   Epoch 0.8111: train_loss/word=3.304 (words=433952, words/sec=5548.90, time=0-00:01:12)   
   Epoch 0.8388: train_loss/word=3.289 (words=445152, words/sec=5865.17, time=0-00:01:14)   
   Epoch 0.8665: train_loss/word=3.282 (words=460096, words/sec=5798.23, time=0-00:01:16)   
   Epoch 0.8942: train_loss/word=3.265 (words=471264, words/sec=6103.64, time=0-00:01:18)   
   Epoch 0.9228: train_loss/word=3.256 (words=485760, words/sec=5928.62, time=0-00:01:21)   
   Epoch 0.9506: train_loss/word=3.242 (words=506400, words/sec=5775.32, time=0-00:01:24)   
   Epoch 0.9783: train_loss/word=3.229 (words=520608, words/sec=5774.63, time=0-00:01:27)   
   Epoch 1.0000: train_loss/word=3.222 (words=532616, words/sec=5314.67, time=0-00:01:29)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 1.0000 dev [auxiliary] Loss: 4.095   
     Epoch 1.0000 dev BLEU4: 0.0155976857219, 0.180571/0.029876/0.007458/0.003455 (BP = 0.807784, ratio=0.82, hyp_len=13773, ref_len=16713) (words=29116, words/sec=405.21, time=0-00:02:41)   
     Epoch 1.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 1.0286: train_loss/word=2.685 (words=11552, words/sec=431.54, time=0-00:03:08)   
   Epoch 1.0563: train_loss/word=2.815 (words=25888, words/sec=5654.70, time=0-00:03:10)   
   Epoch 1.0843: train_loss/word=2.694 (words=39944, words/sec=5718.73, time=0-00:03:13)   
   Epoch 1.1120: train_loss/word=2.732 (words=58696, words/sec=6069.52, time=0-00:03:16)   
   Epoch 1.1398: train_loss/word=2.775 (words=76968, words/sec=5897.43, time=0-00:03:19)   
   Epoch 1.1684: train_loss/word=2.730 (words=87592, words/sec=6104.48, time=0-00:03:21)   
   Epoch 1.1961: train_loss/word=2.747 (words=104968, words/sec=6018.76, time=0-00:03:23)   
   Epoch 1.2238: train_loss/word=2.732 (words=121096, words/sec=6131.04, time=0-00:03:26)   
   Epoch 1.2515: train_loss/word=2.701 (words=133320, words/sec=6035.57, time=0-00:03:28)   
   Epoch 1.2801: train_loss/word=2.720 (words=149896, words/sec=5719.70, time=0-00:03:31)   
   Epoch 1.3079: train_loss/word=2.710 (words=164808, words/sec=5952.46, time=0-00:03:34)   
   Epoch 1.3356: train_loss/word=2.715 (words=185736, words/sec=5827.60, time=0-00:03:37)   
   Epoch 1.3633: train_loss/word=2.700 (words=200200, words/sec=6124.40, time=0-00:03:39)   
   Epoch 1.3919: train_loss/word=2.681 (words=213736, words/sec=6162.30, time=0-00:03:42)   
   Epoch 1.4196: train_loss/word=2.674 (words=227048, words/sec=6081.52, time=0-00:03:44)   
   Epoch 1.4474: train_loss/word=2.657 (words=242664, words/sec=6075.09, time=0-00:03:46)   
   Epoch 1.4751: train_loss/word=2.658 (words=259752, words/sec=5952.22, time=0-00:03:49)   
   Epoch 1.5037: train_loss/word=2.650 (words=273800, words/sec=6109.16, time=0-00:03:52)   
   Epoch 1.5314: train_loss/word=2.666 (words=290824, words/sec=5757.32, time=0-00:03:55)   
   Epoch 1.5591: train_loss/word=2.647 (words=302280, words/sec=6246.20, time=0-00:03:56)   
   Epoch 1.5869: train_loss/word=2.632 (words=317864, words/sec=6130.09, time=0-00:03:59)   
   Epoch 1.6155: train_loss/word=2.631 (words=331112, words/sec=5921.17, time=0-00:04:01)   
   Epoch 1.6432: train_loss/word=2.643 (words=345864, words/sec=5735.70, time=0-00:04:04)   
   Epoch 1.6709: train_loss/word=2.637 (words=359464, words/sec=6084.45, time=0-00:04:06)   
   Epoch 1.6986: train_loss/word=2.638 (words=375240, words/sec=5869.09, time=0-00:04:09)   
   Epoch 1.7273: train_loss/word=2.624 (words=390152, words/sec=6227.31, time=0-00:04:11)   
   Epoch 1.7550: train_loss/word=2.625 (words=404296, words/sec=5747.76, time=0-00:04:14)   
   Epoch 1.7827: train_loss/word=2.612 (words=414952, words/sec=6253.68, time=0-00:04:15)   
   Epoch 1.8104: train_loss/word=2.622 (words=433864, words/sec=5803.98, time=0-00:04:19)   
   Epoch 1.8390: train_loss/word=2.623 (words=448200, words/sec=5856.15, time=0-00:04:21)   
   Epoch 1.8668: train_loss/word=2.620 (words=464008, words/sec=6009.58, time=0-00:04:24)   
   Epoch 1.8945: train_loss/word=2.607 (words=477832, words/sec=6280.55, time=0-00:04:26)   
   Epoch 1.9222: train_loss/word=2.602 (words=493352, words/sec=6054.06, time=0-00:04:28)   
   Epoch 1.9508: train_loss/word=2.594 (words=507240, words/sec=6063.33, time=0-00:04:31)   
   Epoch 1.9785: train_loss/word=2.587 (words=521416, words/sec=6018.49, time=0-00:04:33)   
   Epoch 2.0000: train_loss/word=2.587 (words=532616, words/sec=5883.22, time=0-00:04:35)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 2.0000 dev [auxiliary] Loss: 3.693   
     Epoch 2.0000 dev BLEU4: 0.0155992555215, 0.161465/0.025787/0.005479/0.002596 (BP = 1.000000, ratio=1.04, hyp_len=17366, ref_len=16713) (words=29116, words/sec=325.34, time=0-00:06:04)   
     Epoch 2.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 2.0286: train_loss/word=1.862 (words=10336, words/sec=457.61, time=0-00:06:27)   
   Epoch 2.0563: train_loss/word=2.131 (words=25600, words/sec=5953.55, time=0-00:06:30)   
   Epoch 2.0841: train_loss/word=2.094 (words=36576, words/sec=6107.32, time=0-00:06:31)   
   Epoch 2.1118: train_loss/word=2.019 (words=47968, words/sec=6397.50, time=0-00:06:33)   
   Epoch 2.1404: train_loss/word=2.098 (words=63104, words/sec=5804.26, time=0-00:06:36)   
   Epoch 2.1681: train_loss/word=2.095 (words=74432, words/sec=6115.18, time=0-00:06:38)   
   Epoch 2.1958: train_loss/word=2.187 (words=90912, words/sec=5786.89, time=0-00:06:40)   
   Epoch 2.2236: train_loss/word=2.232 (words=111232, words/sec=5981.42, time=0-00:06:44)   
   Epoch 2.2522: train_loss/word=2.253 (words=127104, words/sec=5919.73, time=0-00:06:47)   
   Epoch 2.2799: train_loss/word=2.230 (words=139776, words/sec=6131.13, time=0-00:06:49)   
   Epoch 2.3076: train_loss/word=2.233 (words=154432, words/sec=5951.61, time=0-00:06:51)   
   Epoch 2.3353: train_loss/word=2.250 (words=169056, words/sec=5941.76, time=0-00:06:53)   
   Epoch 2.3640: train_loss/word=2.219 (words=183424, words/sec=6317.56, time=0-00:06:56)   
   Epoch 2.3917: train_loss/word=2.216 (words=199232, words/sec=6116.98, time=0-00:06:58)   
   Epoch 2.4194: train_loss/word=2.238 (words=219968, words/sec=6024.38, time=0-00:07:02)   
   Epoch 2.4471: train_loss/word=2.250 (words=235328, words/sec=5760.47, time=0-00:07:04)   
   Epoch 2.4757: train_loss/word=2.246 (words=250848, words/sec=6072.13, time=0-00:07:07)   
   Epoch 2.5035: train_loss/word=2.233 (words=264800, words/sec=6235.40, time=0-00:07:09)   
   Epoch 2.5312: train_loss/word=2.238 (words=282688, words/sec=6031.96, time=0-00:07:12)   
   Epoch 2.5589: train_loss/word=2.237 (words=299808, words/sec=5965.07, time=0-00:07:15)   
   Epoch 2.5875: train_loss/word=2.236 (words=313600, words/sec=5924.98, time=0-00:07:17)   
   Epoch 2.6152: train_loss/word=2.228 (words=325888, words/sec=6050.72, time=0-00:07:19)   
   Epoch 2.6430: train_loss/word=2.219 (words=339104, words/sec=6174.47, time=0-00:07:22)   
   Epoch 2.6707: train_loss/word=2.217 (words=356864, words/sec=6075.06, time=0-00:07:25)   
   Epoch 2.6993: train_loss/word=2.216 (words=371072, words/sec=5897.44, time=0-00:07:27)   
   Epoch 2.7270: train_loss/word=2.227 (words=390464, words/sec=5801.70, time=0-00:07:30)   
   Epoch 2.7547: train_loss/word=2.225 (words=405056, words/sec=6076.30, time=0-00:07:33)   
   Epoch 2.7825: train_loss/word=2.220 (words=418016, words/sec=6147.81, time=0-00:07:35)   
   Epoch 2.8111: train_loss/word=2.217 (words=431808, words/sec=5939.98, time=0-00:07:37)   
   Epoch 2.8390: train_loss/word=2.233 (words=451688, words/sec=5557.42, time=0-00:07:41)   
   Epoch 2.8668: train_loss/word=2.226 (words=464584, words/sec=6206.68, time=0-00:07:43)   
   Epoch 2.8945: train_loss/word=2.219 (words=477032, words/sec=6178.44, time=0-00:07:45)   
   Epoch 2.9222: train_loss/word=2.214 (words=490728, words/sec=5997.15, time=0-00:07:47)   
   Epoch 2.9508: train_loss/word=2.221 (words=509768, words/sec=5716.87, time=0-00:07:50)   
   Epoch 2.9785: train_loss/word=2.223 (words=523240, words/sec=5838.74, time=0-00:07:53)   
   Epoch 3.0000: train_loss/word=2.221 (words=532616, words/sec=5919.83, time=0-00:07:54)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 3.0000 dev [auxiliary] Loss: 3.442   
     Epoch 3.0000 dev BLEU4: 0.0210118725424, 0.184716/0.033031/0.008144/0.003923 (BP = 1.000000, ratio=1.06, hyp_len=17757, ref_len=16713) (words=29116, words/sec=329.33, time=0-00:09:23)   
     Epoch 3.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 3.0286: train_loss/word=1.455 (words=12000, words/sec=443.50, time=0-00:09:50)   
   Epoch 3.0566: train_loss/word=1.843 (words=28712, words/sec=5530.98, time=0-00:09:53)   
   Epoch 3.0843: train_loss/word=1.799 (words=39944, words/sec=6088.30, time=0-00:09:55)   
   Epoch 3.1120: train_loss/word=1.874 (words=56360, words/sec=5857.63, time=0-00:09:57)   
   Epoch 3.1398: train_loss/word=1.855 (words=68616, words/sec=6128.66, time=0-00:09:59)   
   Epoch 3.1684: train_loss/word=1.852 (words=82920, words/sec=6099.02, time=0-00:10:02)   
   Epoch 3.1961: train_loss/word=1.818 (words=95144, words/sec=6279.53, time=0-00:10:04)   
   Epoch 3.2238: train_loss/word=1.807 (words=109832, words/sec=6201.83, time=0-00:10:06)   
   Epoch 3.2515: train_loss/word=1.783 (words=121288, words/sec=6218.63, time=0-00:10:08)   
   Epoch 3.2801: train_loss/word=1.842 (words=139784, words/sec=5819.81, time=0-00:10:11)   
   Epoch 3.3079: train_loss/word=1.871 (words=156968, words/sec=5878.46, time=0-00:10:14)   
   Epoch 3.3356: train_loss/word=1.866 (words=171816, words/sec=6156.29, time=0-00:10:16)   
   Epoch 3.3633: train_loss/word=1.889 (words=187368, words/sec=5855.65, time=0-00:10:19)   
   Epoch 3.3919: train_loss/word=1.899 (words=202920, words/sec=5859.13, time=0-00:10:22)   
   Epoch 3.4196: train_loss/word=1.933 (words=221896, words/sec=5658.10, time=0-00:10:25)   
   Epoch 3.4474: train_loss/word=1.918 (words=234952, words/sec=6147.14, time=0-00:10:27)   
   Epoch 3.4751: train_loss/word=1.915 (words=252456, words/sec=6139.32, time=0-00:10:30)   
   Epoch 3.5037: train_loss/word=1.950 (words=274248, words/sec=5762.01, time=0-00:10:34)   
   Epoch 3.5314: train_loss/word=1.957 (words=290504, words/sec=5930.38, time=0-00:10:37)   
   Epoch 3.5591: train_loss/word=1.937 (words=303080, words/sec=6284.46, time=0-00:10:39)   
   Epoch 3.5869: train_loss/word=1.941 (words=320200, words/sec=5981.67, time=0-00:10:41)   
   Epoch 3.6155: train_loss/word=1.944 (words=333128, words/sec=5860.83, time=0-00:10:44)   
   Epoch 3.6432: train_loss/word=1.959 (words=350344, words/sec=5888.81, time=0-00:10:47)   
   Epoch 3.6709: train_loss/word=1.965 (words=366344, words/sec=5965.78, time=0-00:10:49)   
   Epoch 3.6986: train_loss/word=1.954 (words=377224, words/sec=6180.73, time=0-00:10:51)   
   Epoch 3.7273: train_loss/word=1.939 (words=390728, words/sec=6323.34, time=0-00:10:53)   
   Epoch 3.7550: train_loss/word=1.942 (words=406184, words/sec=5873.19, time=0-00:10:56)   
   Epoch 3.7827: train_loss/word=1.932 (words=417512, words/sec=6042.71, time=0-00:10:58)   
   Epoch 3.8104: train_loss/word=1.931 (words=433192, words/sec=6035.01, time=0-00:11:00)   
   Epoch 3.8390: train_loss/word=1.915 (words=446120, words/sec=6361.53, time=0-00:11:02)   
   Epoch 3.8668: train_loss/word=1.914 (words=460584, words/sec=6091.24, time=0-00:11:05)   
   Epoch 3.8945: train_loss/word=1.904 (words=471592, words/sec=6207.97, time=0-00:11:06)   
   Epoch 3.9222: train_loss/word=1.914 (words=489224, words/sec=5656.55, time=0-00:11:10)   
   Epoch 3.9508: train_loss/word=1.919 (words=506184, words/sec=6025.36, time=0-00:11:12)   
   Epoch 3.9785: train_loss/word=1.928 (words=523464, words/sec=5921.19, time=0-00:11:15)   
   Epoch 4.0000: train_loss/word=1.924 (words=532616, words/sec=6111.57, time=0-00:11:17)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 4.0000 dev [auxiliary] Loss: 3.330   
     Epoch 4.0000 dev BLEU4: 0.0297631016159, 0.234470/0.046128/0.013672/0.007124 (BP = 0.929027, ratio=0.93, hyp_len=15567, ref_len=16713) (words=29116, words/sec=345.91, time=0-00:12:41)   
     Epoch 4.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 4.0286: train_loss/word=1.031 (words=9888, words/sec=370.26, time=0-00:13:08)   
   Epoch 4.0563: train_loss/word=1.348 (words=23200, words/sec=6046.61, time=0-00:13:10)   
   Epoch 4.0841: train_loss/word=1.392 (words=36128, words/sec=6155.57, time=0-00:13:12)   
   Epoch 4.1118: train_loss/word=1.427 (words=48864, words/sec=6141.12, time=0-00:13:14)   
   Epoch 4.1404: train_loss/word=1.374 (words=60640, words/sec=6361.23, time=0-00:13:16)   
   Epoch 4.1681: train_loss/word=1.415 (words=73920, words/sec=5975.51, time=0-00:13:18)   
   Epoch 4.1961: train_loss/word=1.523 (words=92328, words/sec=5623.45, time=0-00:13:21)   
   Epoch 4.2238: train_loss/word=1.598 (words=111208, words/sec=5882.71, time=0-00:13:25)   
   Epoch 4.2515: train_loss/word=1.608 (words=125032, words/sec=5819.85, time=0-00:13:27)   
   Epoch 4.2801: train_loss/word=1.601 (words=140264, words/sec=6200.39, time=0-00:13:29)   
   Epoch 4.3079: train_loss/word=1.592 (words=155272, words/sec=6207.47, time=0-00:13:32)   
   Epoch 4.3356: train_loss/word=1.606 (words=171272, words/sec=6011.61, time=0-00:13:35)   
   Epoch 4.3633: train_loss/word=1.590 (words=184264, words/sec=6147.15, time=0-00:13:37)   
   Epoch 4.3919: train_loss/word=1.596 (words=199592, words/sec=6026.75, time=0-00:13:39)   
   Epoch 4.4196: train_loss/word=1.576 (words=210696, words/sec=6261.01, time=0-00:13:41)   
   Epoch 4.4474: train_loss/word=1.607 (words=227496, words/sec=5857.49, time=0-00:13:44)   
   Epoch 4.4751: train_loss/word=1.625 (words=242984, words/sec=5659.68, time=0-00:13:47)   
   Epoch 4.5037: train_loss/word=1.629 (words=256360, words/sec=5826.80, time=0-00:13:49)   
   Epoch 4.5314: train_loss/word=1.633 (words=272008, words/sec=6033.52, time=0-00:13:51)   
   Epoch 4.5591: train_loss/word=1.644 (words=287240, words/sec=5777.12, time=0-00:13:54)   
   Epoch 4.5869: train_loss/word=1.630 (words=298760, words/sec=6287.45, time=0-00:13:56)   
   Epoch 4.6155: train_loss/word=1.617 (words=313544, words/sec=6265.41, time=0-00:13:58)   
   Epoch 4.6432: train_loss/word=1.627 (words=329768, words/sec=5969.21, time=0-00:14:01)   
   Epoch 4.6709: train_loss/word=1.623 (words=344264, words/sec=6071.60, time=0-00:14:03)   
   Epoch 4.6986: train_loss/word=1.628 (words=361064, words/sec=6002.66, time=0-00:14:06)   
   Epoch 4.7273: train_loss/word=1.624 (words=374344, words/sec=6107.63, time=0-00:14:08)   
   Epoch 4.7550: train_loss/word=1.654 (words=395560, words/sec=5684.89, time=0-00:14:12)   
   Epoch 4.7827: train_loss/word=1.649 (words=408808, words/sec=6129.11, time=0-00:14:14)   
   Epoch 4.8104: train_loss/word=1.649 (words=423560, words/sec=5929.12, time=0-00:14:17)   
   Epoch 4.8390: train_loss/word=1.656 (words=439336, words/sec=5887.96, time=0-00:14:19)   
   Epoch 4.8668: train_loss/word=1.656 (words=452552, words/sec=5985.06, time=0-00:14:22)   
   Epoch 4.8945: train_loss/word=1.665 (words=470856, words/sec=5878.22, time=0-00:14:25)   
   Epoch 4.9222: train_loss/word=1.674 (words=487496, words/sec=5889.62, time=0-00:14:28)   
   Epoch 4.9508: train_loss/word=1.679 (words=504808, words/sec=6034.38, time=0-00:14:30)   
   Epoch 4.9785: train_loss/word=1.677 (words=521000, words/sec=6163.41, time=0-00:14:33)   
   Epoch 5.0000: train_loss/word=1.680 (words=532616, words/sec=5982.88, time=0-00:14:35)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 5.0000 dev [auxiliary] Loss: 3.241   
     Epoch 5.0000 dev BLEU4: 0.0289972348546, 0.215652/0.041758/0.012379/0.006342 (BP = 1.000000, ratio=1.10, hyp_len=18349, ref_len=16713) (words=29116, words/sec=300.05, time=0-00:16:12)   
   Epoch 5.0286: train_loss/word=1.571 (words=17600, words/sec=5882.69, time=0-00:16:15)   
   Epoch 5.0563: train_loss/word=1.595 (words=34528, words/sec=5967.66, time=0-00:16:18)   
   Epoch 5.0841: train_loss/word=1.629 (words=53472, words/sec=6045.76, time=0-00:16:21)   
   Epoch 5.1118: train_loss/word=1.513 (words=63456, words/sec=6156.79, time=0-00:16:23)   
   Epoch 5.1404: train_loss/word=1.564 (words=84992, words/sec=5923.16, time=0-00:16:26)   
   Epoch 5.1681: train_loss/word=1.518 (words=100000, words/sec=6276.07, time=0-00:16:29)   
   Epoch 5.1958: train_loss/word=1.487 (words=112160, words/sec=6202.21, time=0-00:16:31)   
   Epoch 5.2236: train_loss/word=1.533 (words=129600, words/sec=5629.14, time=0-00:16:34)   
   Epoch 5.2522: train_loss/word=1.520 (words=144224, words/sec=6071.53, time=0-00:16:36)   
   Epoch 5.2799: train_loss/word=1.539 (words=160320, words/sec=5733.59, time=0-00:16:39)   
   Epoch 5.3076: train_loss/word=1.524 (words=174176, words/sec=6114.06, time=0-00:16:41)   
   Epoch 5.3353: train_loss/word=1.506 (words=187008, words/sec=6108.10, time=0-00:16:43)   
   Epoch 5.3640: train_loss/word=1.496 (words=202688, words/sec=6174.73, time=0-00:16:46)   
   Epoch 5.3917: train_loss/word=1.511 (words=219360, words/sec=5878.18, time=0-00:16:49)   
   Epoch 5.4194: train_loss/word=1.506 (words=236768, words/sec=6086.17, time=0-00:16:52)   
   Epoch 5.4471: train_loss/word=1.512 (words=252416, words/sec=5693.45, time=0-00:16:54)   
   Epoch 5.4757: train_loss/word=1.498 (words=264800, words/sec=6155.39, time=0-00:16:56)   
   Epoch 5.5035: train_loss/word=1.483 (words=276512, words/sec=6156.24, time=0-00:16:58)   
   Epoch 5.5312: train_loss/word=1.491 (words=292704, words/sec=5844.85, time=0-00:17:01)   
   Epoch 5.5589: train_loss/word=1.480 (words=304832, words/sec=6149.30, time=0-00:17:03)   
   Epoch 5.5875: train_loss/word=1.482 (words=319776, words/sec=6015.47, time=0-00:17:05)   
   Epoch 5.6152: train_loss/word=1.507 (words=338784, words/sec=5787.70, time=0-00:17:09)   
   Epoch 5.6432: train_loss/word=1.502 (words=351496, words/sec=5567.90, time=0-00:17:11)   
   Epoch 5.6709: train_loss/word=1.498 (words=366056, words/sec=6050.01, time=0-00:17:13)   
   Epoch 5.6986: train_loss/word=1.489 (words=379272, words/sec=6215.21, time=0-00:17:16)   
   Epoch 5.7273: train_loss/word=1.494 (words=394792, words/sec=5891.25, time=0-00:17:18)   
   Epoch 5.7550: train_loss/word=1.491 (words=408680, words/sec=6091.50, time=0-00:17:20)   
   Epoch 5.7827: train_loss/word=1.484 (words=420616, words/sec=6065.03, time=0-00:17:22)   
   Epoch 5.8104: train_loss/word=1.497 (words=436488, words/sec=5551.93, time=0-00:17:25)   
   Epoch 5.8390: train_loss/word=1.494 (words=449544, words/sec=6004.51, time=0-00:17:27)   
   Epoch 5.8668: train_loss/word=1.499 (words=465384, words/sec=5890.06, time=0-00:17:30)   
   Epoch 5.8945: train_loss/word=1.494 (words=480136, words/sec=6184.01, time=0-00:17:33)   
   Epoch 5.9222: train_loss/word=1.489 (words=493288, words/sec=6140.48, time=0-00:17:35)   
   Epoch 5.9508: train_loss/word=1.483 (words=508936, words/sec=6198.58, time=0-00:17:37)   
   Epoch 5.9785: train_loss/word=1.482 (words=522984, words/sec=6062.31, time=0-00:17:39)   
   Epoch 6.0000: train_loss/word=1.475 (words=532616, words/sec=6361.07, time=0-00:17:41)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 6.0000 dev [auxiliary] Loss: 3.232   
     Epoch 6.0000 dev BLEU4: 0.0288401853376, 0.224434/0.043422/0.012570/0.005648 (BP = 1.000000, ratio=1.05, hyp_len=17533, ref_len=16713) (words=29116, words/sec=310.94, time=0-00:19:15)   
   Epoch 6.0286: train_loss/word=1.237 (words=15488, words/sec=6019.35, time=0-00:19:17)   
   Epoch 6.0563: train_loss/word=1.172 (words=28384, words/sec=6073.43, time=0-00:19:19)   
   Epoch 6.0841: train_loss/word=1.210 (words=43520, words/sec=6035.70, time=0-00:19:22)   
   Epoch 6.1118: train_loss/word=1.174 (words=56000, words/sec=6135.89, time=0-00:19:24)   
   Epoch 6.1404: train_loss/word=1.150 (words=68832, words/sec=6252.91, time=0-00:19:26)   
   Epoch 6.1681: train_loss/word=1.192 (words=83584, words/sec=5989.68, time=0-00:19:28)   
   Epoch 6.1958: train_loss/word=1.179 (words=97056, words/sec=6135.55, time=0-00:19:31)   
   Epoch 6.2236: train_loss/word=1.149 (words=110048, words/sec=6321.71, time=0-00:19:33)   
   Epoch 6.2522: train_loss/word=1.157 (words=125152, words/sec=6167.48, time=0-00:19:35)   
   Epoch 6.2799: train_loss/word=1.163 (words=139968, words/sec=6094.45, time=0-00:19:38)   
   Epoch 6.3076: train_loss/word=1.190 (words=157408, words/sec=6007.23, time=0-00:19:40)   
   Epoch 6.3353: train_loss/word=1.161 (words=167136, words/sec=6282.76, time=0-00:19:42)   
   Epoch 6.3640: train_loss/word=1.199 (words=184288, words/sec=5705.30, time=0-00:19:45)   
   Epoch 6.3917: train_loss/word=1.249 (words=203392, words/sec=5652.14, time=0-00:19:48)   
   Epoch 6.4194: train_loss/word=1.263 (words=220032, words/sec=5971.58, time=0-00:19:51)   
   Epoch 6.4471: train_loss/word=1.251 (words=233984, words/sec=6300.38, time=0-00:19:53)   
   Epoch 6.4757: train_loss/word=1.246 (words=245984, words/sec=5975.99, time=0-00:19:55)   
   Epoch 6.5035: train_loss/word=1.262 (words=263296, words/sec=5916.92, time=0-00:19:58)   
   Epoch 6.5312: train_loss/word=1.257 (words=277184, words/sec=6166.80, time=0-00:20:01)   
   Epoch 6.5589: train_loss/word=1.266 (words=292384, words/sec=5928.34, time=0-00:20:03)   
   Epoch 6.5875: train_loss/word=1.276 (words=308928, words/sec=5853.99, time=0-00:20:06)   
   Epoch 6.6155: train_loss/word=1.277 (words=322376, words/sec=5445.87, time=0-00:20:08)   
   Epoch 6.6432: train_loss/word=1.285 (words=338984, words/sec=5931.23, time=0-00:20:11)   
   Epoch 6.6709: train_loss/word=1.270 (words=349800, words/sec=6252.27, time=0-00:20:13)   
   Epoch 6.6986: train_loss/word=1.280 (words=367432, words/sec=6006.06, time=0-00:20:16)   
   Epoch 6.7273: train_loss/word=1.279 (words=381032, words/sec=5942.03, time=0-00:20:18)   
   Epoch 6.7550: train_loss/word=1.273 (words=393064, words/sec=5991.53, time=0-00:20:20)   
   Epoch 6.7827: train_loss/word=1.273 (words=406856, words/sec=5973.23, time=0-00:20:22)   
   Epoch 6.8104: train_loss/word=1.280 (words=425928, words/sec=6011.48, time=0-00:20:26)   
   Epoch 6.8390: train_loss/word=1.284 (words=443240, words/sec=5775.80, time=0-00:20:29)   
   Epoch 6.8668: train_loss/word=1.278 (words=455688, words/sec=6094.34, time=0-00:20:31)   
   Epoch 6.8945: train_loss/word=1.288 (words=473128, words/sec=5950.36, time=0-00:20:34)   
   Epoch 6.9222: train_loss/word=1.298 (words=490984, words/sec=5892.42, time=0-00:20:37)   
   Epoch 6.9508: train_loss/word=1.306 (words=507784, words/sec=5769.68, time=0-00:20:40)   
   Epoch 6.9785: train_loss/word=1.302 (words=519144, words/sec=5955.16, time=0-00:20:41)   
   Epoch 7.0000: train_loss/word=1.309 (words=532616, words/sec=5788.40, time=0-00:20:44)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 7.0000 dev [auxiliary] Loss: 3.181   
     Epoch 7.0000 dev BLEU4: 0.0343372922591, 0.246609/0.054345/0.017603/0.008439 (BP = 0.914124, ratio=0.92, hyp_len=15336, ref_len=16713) (words=29116, words/sec=312.74, time=0-00:22:17)   
     Epoch 7.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 7.0286: train_loss/word=0.648 (words=10368, words/sec=655.86, time=0-00:22:33)   
   Epoch 7.0566: train_loss/word=1.061 (words=26280, words/sec=5455.04, time=0-00:22:36)   
   Epoch 7.0843: train_loss/word=1.071 (words=40040, words/sec=6033.85, time=0-00:22:38)   
   Epoch 7.1120: train_loss/word=1.060 (words=53704, words/sec=6063.68, time=0-00:22:40)   
   Epoch 7.1398: train_loss/word=1.128 (words=70216, words/sec=5847.99, time=0-00:22:43)   
   Epoch 7.1684: train_loss/word=1.095 (words=82376, words/sec=6117.56, time=0-00:22:45)   
   Epoch 7.1961: train_loss/word=1.115 (words=96904, words/sec=5876.73, time=0-00:22:47)   
   Epoch 7.2238: train_loss/word=1.092 (words=111400, words/sec=6207.25, time=0-00:22:50)   
   Epoch 7.2515: train_loss/word=1.090 (words=126312, words/sec=5964.27, time=0-00:22:52)   
   Epoch 7.2801: train_loss/word=1.104 (words=142696, words/sec=6049.60, time=0-00:22:55)   
   Epoch 7.3079: train_loss/word=1.107 (words=156712, words/sec=6010.44, time=0-00:22:57)   
   Epoch 7.3356: train_loss/word=1.126 (words=173416, words/sec=6009.49, time=0-00:23:00)   
   Epoch 7.3633: train_loss/word=1.108 (words=184616, words/sec=6081.87, time=0-00:23:02)   
   Epoch 7.3919: train_loss/word=1.123 (words=201736, words/sec=6115.14, time=0-00:23:05)   
   Epoch 7.4196: train_loss/word=1.154 (words=220392, words/sec=5826.23, time=0-00:23:08)   
   Epoch 7.4474: train_loss/word=1.138 (words=232872, words/sec=6238.44, time=0-00:23:10)   
   Epoch 7.4751: train_loss/word=1.161 (words=251880, words/sec=5846.60, time=0-00:23:13)   
   Epoch 7.5037: train_loss/word=1.147 (words=266824, words/sec=6150.78, time=0-00:23:16)   
   Epoch 7.5314: train_loss/word=1.135 (words=280168, words/sec=6282.63, time=0-00:23:18)   
   Epoch 7.5591: train_loss/word=1.155 (words=298312, words/sec=5636.62, time=0-00:23:21)   
   Epoch 7.5869: train_loss/word=1.155 (words=312808, words/sec=6033.75, time=0-00:23:23)   
   Epoch 7.6155: train_loss/word=1.149 (words=325800, words/sec=6093.24, time=0-00:23:26)   
   Epoch 7.6432: train_loss/word=1.164 (words=341704, words/sec=5817.43, time=0-00:23:28)   
   Epoch 7.6709: train_loss/word=1.161 (words=357448, words/sec=6169.11, time=0-00:23:31)   
   Epoch 7.6986: train_loss/word=1.156 (words=371080, words/sec=6165.64, time=0-00:23:33)   
   Epoch 7.7273: train_loss/word=1.161 (words=389192, words/sec=6066.54, time=0-00:23:36)   
   Epoch 7.7550: train_loss/word=1.155 (words=402920, words/sec=6163.09, time=0-00:23:38)   
   Epoch 7.7827: train_loss/word=1.148 (words=415272, words/sec=6156.16, time=0-00:23:40)   
   Epoch 7.8104: train_loss/word=1.143 (words=429480, words/sec=6253.91, time=0-00:23:42)   
   Epoch 7.8390: train_loss/word=1.143 (words=443464, words/sec=5941.57, time=0-00:23:45)   
   Epoch 7.8668: train_loss/word=1.139 (words=455048, words/sec=5970.55, time=0-00:23:47)   
   Epoch 7.8945: train_loss/word=1.151 (words=473256, words/sec=5975.05, time=0-00:23:50)   
   Epoch 7.9222: train_loss/word=1.155 (words=488328, words/sec=5887.52, time=0-00:23:52)   
   Epoch 7.9508: train_loss/word=1.166 (words=507112, words/sec=5850.77, time=0-00:23:56)   
   Epoch 7.9785: train_loss/word=1.163 (words=520008, words/sec=5909.63, time=0-00:23:58)   
   Epoch 8.0000: train_loss/word=1.164 (words=532616, words/sec=6060.93, time=0-00:24:00)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 8.0000 dev [auxiliary] Loss: 3.184   
     Epoch 8.0000 dev BLEU4: 0.0329724059479, 0.242127/0.051417/0.016618/0.007424 (BP = 0.936625, ratio=0.94, hyp_len=15686, ref_len=16713) (words=29116, words/sec=332.89, time=0-00:25:27)   
   Epoch 8.0286: train_loss/word=0.806 (words=14336, words/sec=6126.62, time=0-00:25:30)   
   Epoch 8.0563: train_loss/word=0.986 (words=30368, words/sec=5862.23, time=0-00:25:32)   
   Epoch 8.0841: train_loss/word=0.927 (words=42816, words/sec=6112.70, time=0-00:25:34)   
   Epoch 8.1118: train_loss/word=1.008 (words=60768, words/sec=6034.08, time=0-00:25:37)   
   Epoch 8.1404: train_loss/word=1.102 (words=80480, words/sec=5821.06, time=0-00:25:41)   
   Epoch 8.1681: train_loss/word=1.108 (words=96640, words/sec=5815.74, time=0-00:25:44)   
   Epoch 8.1958: train_loss/word=1.100 (words=109856, words/sec=5973.54, time=0-00:25:46)   
   Epoch 8.2236: train_loss/word=1.089 (words=123360, words/sec=5987.44, time=0-00:25:48)   
   Epoch 8.2522: train_loss/word=1.056 (words=135328, words/sec=6009.91, time=0-00:25:50)   
   Epoch 8.2799: train_loss/word=1.051 (words=150848, words/sec=6043.29, time=0-00:25:53)   
   Epoch 8.3076: train_loss/word=1.032 (words=164128, words/sec=6091.00, time=0-00:25:55)   
   Epoch 8.3353: train_loss/word=1.019 (words=178080, words/sec=6043.92, time=0-00:25:57)   
   Epoch 8.3640: train_loss/word=1.027 (words=193696, words/sec=5968.90, time=0-00:26:00)   
   Epoch 8.3917: train_loss/word=1.027 (words=209760, words/sec=6127.43, time=0-00:26:02)   
   Epoch 8.4194: train_loss/word=1.009 (words=221152, words/sec=6163.93, time=0-00:26:04)   
   Epoch 8.4471: train_loss/word=1.014 (words=236960, words/sec=6001.31, time=0-00:26:07)   
   Epoch 8.4757: train_loss/word=1.009 (words=250784, words/sec=6008.59, time=0-00:26:09)   
   Epoch 8.5035: train_loss/word=0.992 (words=262272, words/sec=6335.32, time=0-00:26:11)   
   Epoch 8.5312: train_loss/word=1.001 (words=276864, words/sec=5904.62, time=0-00:26:13)   
   Epoch 8.5589: train_loss/word=1.009 (words=293504, words/sec=5941.06, time=0-00:26:16)   
   Epoch 8.5875: train_loss/word=1.019 (words=309696, words/sec=5796.02, time=0-00:26:19)   
   Epoch 8.6152: train_loss/word=1.030 (words=326912, words/sec=6033.78, time=0-00:26:22)   
   Epoch 8.6430: train_loss/word=1.016 (words=338976, words/sec=6280.02, time=0-00:26:24)   
   Epoch 8.6707: train_loss/word=1.018 (words=354304, words/sec=5892.66, time=0-00:26:26)   
   Epoch 8.6993: train_loss/word=1.030 (words=372576, words/sec=5888.30, time=0-00:26:29)   
   Epoch 8.7270: train_loss/word=1.016 (words=383232, words/sec=6165.58, time=0-00:26:31)   
   Epoch 8.7547: train_loss/word=1.022 (words=398720, words/sec=5975.40, time=0-00:26:34)   
   Epoch 8.7825: train_loss/word=1.009 (words=409440, words/sec=6384.52, time=0-00:26:35)   
   Epoch 8.8111: train_loss/word=1.016 (words=424992, words/sec=5967.01, time=0-00:26:38)   
   Epoch 8.8388: train_loss/word=1.040 (words=447488, words/sec=5751.69, time=0-00:26:42)   
   Epoch 8.8665: train_loss/word=1.048 (words=463008, words/sec=5859.17, time=0-00:26:45)   
   Epoch 8.8942: train_loss/word=1.054 (words=479584, words/sec=5826.58, time=0-00:26:47)   
   Epoch 8.9228: train_loss/word=1.044 (words=489600, words/sec=6214.74, time=0-00:26:49)   
   Epoch 8.9508: train_loss/word=1.043 (words=506056, words/sec=5802.01, time=0-00:26:52)   
   Epoch 8.9785: train_loss/word=1.039 (words=520360, words/sec=6305.35, time=0-00:26:54)   
   Epoch 9.0000: train_loss/word=1.041 (words=532616, words/sec=5971.53, time=0-00:26:56)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 9.0000 dev [auxiliary] Loss: 3.209   
     Epoch 9.0000 dev BLEU4: 0.0349077180037, 0.255591/0.054619/0.016935/0.007851 (BP = 0.945747, ratio=0.95, hyp_len=15830, ref_len=16713) (words=29116, words/sec=329.61, time=0-00:28:25)   
     Epoch 9.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 9.0286: train_loss/word=1.184 (words=20832, words/sec=730.66, time=0-00:28:53)   
   Epoch 9.0563: train_loss/word=0.963 (words=31680, words/sec=6178.09, time=0-00:28:55)   
   Epoch 9.0841: train_loss/word=0.828 (words=42944, words/sec=6404.14, time=0-00:28:57)   
   Epoch 9.1118: train_loss/word=0.897 (words=61120, words/sec=6106.22, time=0-00:29:00)   
   Epoch 9.1404: train_loss/word=0.935 (words=78016, words/sec=5967.42, time=0-00:29:02)   
   Epoch 9.1681: train_loss/word=0.953 (words=96896, words/sec=6003.40, time=0-00:29:06)   
   Epoch 9.1958: train_loss/word=0.948 (words=109952, words/sec=5934.53, time=0-00:29:08)   
   Epoch 9.2236: train_loss/word=0.920 (words=121600, words/sec=6128.85, time=0-00:29:10)   
   Epoch 9.2515: train_loss/word=0.952 (words=139816, words/sec=5575.30, time=0-00:29:13)   
   Epoch 9.2801: train_loss/word=0.955 (words=156296, words/sec=5983.57, time=0-00:29:16)   
   Epoch 9.3079: train_loss/word=0.948 (words=171496, words/sec=6089.68, time=0-00:29:18)   
   Epoch 9.3356: train_loss/word=0.928 (words=183528, words/sec=6172.03, time=0-00:29:20)   
   Epoch 9.3633: train_loss/word=0.954 (words=200712, words/sec=5765.85, time=0-00:29:23)   
   Epoch 9.3919: train_loss/word=0.953 (words=217096, words/sec=5916.44, time=0-00:29:26)   
   Epoch 9.4196: train_loss/word=0.953 (words=231464, words/sec=6051.76, time=0-00:29:28)   
   Epoch 9.4474: train_loss/word=0.956 (words=246184, words/sec=5953.86, time=0-00:29:31)   
   Epoch 9.4751: train_loss/word=0.952 (words=261096, words/sec=6064.48, time=0-00:29:33)   
   Epoch 9.5037: train_loss/word=0.943 (words=275368, words/sec=6140.44, time=0-00:29:36)   
   Epoch 9.5314: train_loss/word=0.946 (words=288968, words/sec=5827.69, time=0-00:29:38)   
   Epoch 9.5591: train_loss/word=0.944 (words=302536, words/sec=6046.54, time=0-00:29:40)   
   Epoch 9.5869: train_loss/word=0.929 (words=315432, words/sec=6301.56, time=0-00:29:42)   
   Epoch 9.6155: train_loss/word=0.933 (words=330920, words/sec=5841.40, time=0-00:29:45)   
   Epoch 9.6432: train_loss/word=0.931 (words=345000, words/sec=6119.56, time=0-00:29:47)   
   Epoch 9.6709: train_loss/word=0.936 (words=359688, words/sec=5900.90, time=0-00:29:50)   
   Epoch 9.6986: train_loss/word=0.930 (words=372360, words/sec=6124.53, time=0-00:29:52)   
   Epoch 9.7273: train_loss/word=0.933 (words=388680, words/sec=5904.79, time=0-00:29:54)   
   Epoch 9.7550: train_loss/word=0.930 (words=403592, words/sec=6253.27, time=0-00:29:57)   
   Epoch 9.7827: train_loss/word=0.920 (words=414504, words/sec=6132.84, time=0-00:29:59)   
   Epoch 9.8104: train_loss/word=0.932 (words=431080, words/sec=5684.51, time=0-00:30:01)   
   Epoch 9.8390: train_loss/word=0.941 (words=448168, words/sec=5780.85, time=0-00:30:04)   
   Epoch 9.8668: train_loss/word=0.938 (words=462440, words/sec=6202.59, time=0-00:30:07)   
   Epoch 9.8945: train_loss/word=0.947 (words=478184, words/sec=5669.51, time=0-00:30:10)   
   Epoch 9.9222: train_loss/word=0.941 (words=491048, words/sec=6170.85, time=0-00:30:12)   
   Epoch 9.9508: train_loss/word=0.940 (words=506952, words/sec=6170.47, time=0-00:30:14)   
   Epoch 9.9785: train_loss/word=0.934 (words=517352, words/sec=6094.13, time=0-00:30:16)   
   Epoch 10.0000: train_loss/word=0.937 (words=532616, words/sec=6110.30, time=0-00:30:18)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 10.0000 dev [auxiliary] Loss: 3.252   
     Epoch 10.0000 dev BLEU4: 0.0392028085808, 0.258338/0.058895/0.020796/0.010378 (BP = 0.920924, ratio=0.92, hyp_len=15441, ref_len=16713) (words=29116, words/sec=335.72, time=0-00:31:45)   
     Epoch 10.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 10.0286: train_loss/word=0.481 (words=12288, words/sec=587.42, time=0-00:32:06)   
   Epoch 10.0563: train_loss/word=0.739 (words=27872, words/sec=5765.34, time=0-00:32:09)   
   Epoch 10.0841: train_loss/word=0.730 (words=41248, words/sec=6023.40, time=0-00:32:11)   
   Epoch 10.1118: train_loss/word=0.693 (words=53728, words/sec=6232.46, time=0-00:32:13)   
   Epoch 10.1404: train_loss/word=0.698 (words=68832, words/sec=6125.59, time=0-00:32:15)   
   Epoch 10.1681: train_loss/word=0.727 (words=84928, words/sec=6053.74, time=0-00:32:18)   
   Epoch 10.1961: train_loss/word=0.714 (words=96936, words/sec=5651.30, time=0-00:32:20)   
   Epoch 10.2238: train_loss/word=0.705 (words=110504, words/sec=6182.90, time=0-00:32:22)   
   Epoch 10.2515: train_loss/word=0.711 (words=123848, words/sec=6086.48, time=0-00:32:25)   
   Epoch 10.2801: train_loss/word=0.723 (words=139240, words/sec=6062.24, time=0-00:32:27)   
   Epoch 10.3079: train_loss/word=0.746 (words=155400, words/sec=5936.16, time=0-00:32:30)   
   Epoch 10.3356: train_loss/word=0.756 (words=169704, words/sec=5997.49, time=0-00:32:32)   
   Epoch 10.3633: train_loss/word=0.776 (words=187816, words/sec=6088.19, time=0-00:32:35)   
   Epoch 10.3919: train_loss/word=0.784 (words=201768, words/sec=5999.46, time=0-00:32:38)   
   Epoch 10.4196: train_loss/word=0.800 (words=216360, words/sec=5787.77, time=0-00:32:40)   
   Epoch 10.4474: train_loss/word=0.800 (words=231720, words/sec=6113.01, time=0-00:32:43)   
   Epoch 10.4751: train_loss/word=0.808 (words=250504, words/sec=6114.36, time=0-00:32:46)   
   Epoch 10.5037: train_loss/word=0.806 (words=265448, words/sec=5965.15, time=0-00:32:48)   
   Epoch 10.5314: train_loss/word=0.795 (words=278536, words/sec=6287.82, time=0-00:32:50)   
   Epoch 10.5591: train_loss/word=0.807 (words=294664, words/sec=5965.99, time=0-00:32:53)   
   Epoch 10.5869: train_loss/word=0.810 (words=311528, words/sec=6178.03, time=0-00:32:56)   
   Epoch 10.6155: train_loss/word=0.805 (words=324392, words/sec=6050.43, time=0-00:32:58)   
   Epoch 10.6432: train_loss/word=0.816 (words=340264, words/sec=5814.25, time=0-00:33:01)   
   Epoch 10.6709: train_loss/word=0.805 (words=350888, words/sec=6138.45, time=0-00:33:02)   
   Epoch 10.6986: train_loss/word=0.818 (words=369096, words/sec=5782.65, time=0-00:33:05)   
   Epoch 10.7273: train_loss/word=0.811 (words=381544, words/sec=6149.46, time=0-00:33:07)   
   Epoch 10.7550: train_loss/word=0.809 (words=395848, words/sec=6080.33, time=0-00:33:10)   
   Epoch 10.7827: train_loss/word=0.816 (words=411688, words/sec=5764.63, time=0-00:33:13)   
   Epoch 10.8104: train_loss/word=0.819 (words=426952, words/sec=5952.68, time=0-00:33:15)   
   Epoch 10.8390: train_loss/word=0.819 (words=439528, words/sec=5911.71, time=0-00:33:17)   
   Epoch 10.8668: train_loss/word=0.840 (words=460648, words/sec=5790.57, time=0-00:33:21)   
   Epoch 10.8945: train_loss/word=0.849 (words=476136, words/sec=5656.40, time=0-00:33:24)   
   Epoch 10.9222: train_loss/word=0.853 (words=491816, words/sec=5801.13, time=0-00:33:26)   
   Epoch 10.9508: train_loss/word=0.857 (words=512136, words/sec=6024.16, time=0-00:33:30)   
   Epoch 10.9785: train_loss/word=0.847 (words=520488, words/sec=6375.84, time=0-00:33:31)   
   Epoch 11.0000: train_loss/word=0.845 (words=532616, words/sec=6230.06, time=0-00:33:33)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 11.0000 dev [auxiliary] Loss: 3.272   
     Epoch 11.0000 dev BLEU4: 0.0338288615333, 0.252059/0.055193/0.017591/0.008311 (BP = 0.895784, ratio=0.90, hyp_len=15056, ref_len=16713) (words=29116, words/sec=305.48, time=0-00:35:08)   
   Epoch 11.0286: train_loss/word=0.674 (words=14560, words/sec=5793.95, time=0-00:35:11)   
   Epoch 11.0563: train_loss/word=0.612 (words=27712, words/sec=6216.36, time=0-00:35:13)   
   Epoch 11.0841: train_loss/word=0.566 (words=41504, words/sec=6277.28, time=0-00:35:15)   
   Epoch 11.1118: train_loss/word=0.612 (words=55584, words/sec=5843.74, time=0-00:35:17)   
   Epoch 11.1404: train_loss/word=0.763 (words=78752, words/sec=5622.24, time=0-00:35:22)   
   Epoch 11.1681: train_loss/word=0.774 (words=95840, words/sec=5963.17, time=0-00:35:24)   
   Epoch 11.1958: train_loss/word=0.746 (words=109408, words/sec=6163.88, time=0-00:35:27)   
   Epoch 11.2236: train_loss/word=0.734 (words=122944, words/sec=6067.31, time=0-00:35:29)   
   Epoch 11.2522: train_loss/word=0.711 (words=135904, words/sec=5973.53, time=0-00:35:31)   
   Epoch 11.2799: train_loss/word=0.709 (words=147232, words/sec=5931.45, time=0-00:35:33)   
   Epoch 11.3076: train_loss/word=0.717 (words=161504, words/sec=5946.84, time=0-00:35:35)   
   Epoch 11.3353: train_loss/word=0.750 (words=180224, words/sec=5934.51, time=0-00:35:39)   
   Epoch 11.3640: train_loss/word=0.751 (words=196640, words/sec=6104.44, time=0-00:35:41)   
   Epoch 11.3917: train_loss/word=0.725 (words=207200, words/sec=6376.88, time=0-00:35:43)   
   Epoch 11.4194: train_loss/word=0.723 (words=219200, words/sec=6121.43, time=0-00:35:45)   
   Epoch 11.4471: train_loss/word=0.721 (words=233536, words/sec=6047.19, time=0-00:35:47)   
   Epoch 11.4757: train_loss/word=0.737 (words=251264, words/sec=5866.97, time=0-00:35:50)   
   Epoch 11.5035: train_loss/word=0.737 (words=267232, words/sec=6143.29, time=0-00:35:53)   
   Epoch 11.5312: train_loss/word=0.733 (words=281504, words/sec=6062.86, time=0-00:35:55)   
   Epoch 11.5589: train_loss/word=0.740 (words=296640, words/sec=5767.93, time=0-00:35:58)   
   Epoch 11.5875: train_loss/word=0.741 (words=314048, words/sec=6052.87, time=0-00:36:01)   
   Epoch 11.6152: train_loss/word=0.739 (words=327584, words/sec=5996.54, time=0-00:36:03)   
   Epoch 11.6430: train_loss/word=0.734 (words=340736, words/sec=6206.60, time=0-00:36:05)   
   Epoch 11.6707: train_loss/word=0.737 (words=354752, words/sec=5949.24, time=0-00:36:07)   
   Epoch 11.6993: train_loss/word=0.730 (words=367232, words/sec=6171.37, time=0-00:36:09)   
   Epoch 11.7270: train_loss/word=0.744 (words=386304, words/sec=5885.29, time=0-00:36:13)   
   Epoch 11.7550: train_loss/word=0.748 (words=403656, words/sec=5688.86, time=0-00:36:16)   
   Epoch 11.7827: train_loss/word=0.746 (words=416168, words/sec=6024.38, time=0-00:36:18)   
   Epoch 11.8104: train_loss/word=0.740 (words=429672, words/sec=6227.22, time=0-00:36:20)   
   Epoch 11.8390: train_loss/word=0.740 (words=443528, words/sec=5902.18, time=0-00:36:22)   
   Epoch 11.8668: train_loss/word=0.751 (words=459368, words/sec=5681.27, time=0-00:36:25)   
   Epoch 11.8945: train_loss/word=0.749 (words=475112, words/sec=6047.84, time=0-00:36:28)   
   Epoch 11.9222: train_loss/word=0.759 (words=492136, words/sec=5794.22, time=0-00:36:31)   
   Epoch 11.9508: train_loss/word=0.763 (words=507592, words/sec=5979.55, time=0-00:36:33)   
   Epoch 11.9785: train_loss/word=0.759 (words=520296, words/sec=6186.74, time=0-00:36:35)   
   Epoch 12.0000: train_loss/word=0.760 (words=532616, words/sec=5943.82, time=0-00:36:37)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 12.0000 dev [auxiliary] Loss: 3.324   
     Epoch 12.0000 dev BLEU4: 0.03790513104, 0.266469/0.060791/0.020063/0.009431 (BP = 0.905909, ratio=0.91, hyp_len=15210, ref_len=16713) (words=29116, words/sec=330.85, time=0-00:38:05)   
   Epoch 12.0286: train_loss/word=0.556 (words=13888, words/sec=5975.98, time=0-00:38:08)   
   Epoch 12.0563: train_loss/word=0.562 (words=28608, words/sec=6155.71, time=0-00:38:10)   
   Epoch 12.0841: train_loss/word=0.571 (words=44736, words/sec=6193.57, time=0-00:38:13)   
   Epoch 12.1118: train_loss/word=0.607 (words=59232, words/sec=5771.37, time=0-00:38:15)   
   Epoch 12.1404: train_loss/word=0.649 (words=77792, words/sec=6073.61, time=0-00:38:18)   
   Epoch 12.1681: train_loss/word=0.684 (words=93440, words/sec=5774.44, time=0-00:38:21)   
   Epoch 12.1958: train_loss/word=0.701 (words=110592, words/sec=6010.02, time=0-00:38:24)   
   Epoch 12.2236: train_loss/word=0.707 (words=125568, words/sec=5948.14, time=0-00:38:26)   
   Epoch 12.2522: train_loss/word=0.706 (words=141472, words/sec=5931.93, time=0-00:38:29)   
   Epoch 12.2799: train_loss/word=0.708 (words=157184, words/sec=5841.30, time=0-00:38:32)   
   Epoch 12.3076: train_loss/word=0.718 (words=172640, words/sec=5858.79, time=0-00:38:34)   
   Epoch 12.3353: train_loss/word=0.704 (words=186624, words/sec=6189.26, time=0-00:38:37)   
   Epoch 12.3640: train_loss/word=0.712 (words=203840, words/sec=5877.45, time=0-00:38:40)   
   Epoch 12.3917: train_loss/word=0.699 (words=216192, words/sec=5975.16, time=0-00:38:42)   
   Epoch 12.4194: train_loss/word=0.680 (words=225984, words/sec=6390.44, time=0-00:38:43)   
   Epoch 12.4471: train_loss/word=0.673 (words=239840, words/sec=6112.49, time=0-00:38:45)   
   Epoch 12.4757: train_loss/word=0.681 (words=257216, words/sec=5908.07, time=0-00:38:48)   
   Epoch 12.5035: train_loss/word=0.683 (words=274240, words/sec=5967.24, time=0-00:38:51)   
   Epoch 12.5312: train_loss/word=0.686 (words=289216, words/sec=5899.96, time=0-00:38:54)   
   Epoch 12.5589: train_loss/word=0.681 (words=304416, words/sec=6051.89, time=0-00:38:56)   
   Epoch 12.5875: train_loss/word=0.684 (words=319136, words/sec=5829.67, time=0-00:38:59)   
   Epoch 12.6152: train_loss/word=0.696 (words=334880, words/sec=5725.74, time=0-00:39:02)   
   Epoch 12.6430: train_loss/word=0.695 (words=350944, words/sec=5981.64, time=0-00:39:04)   
   Epoch 12.6707: train_loss/word=0.697 (words=365984, words/sec=5954.89, time=0-00:39:07)   
   Epoch 12.6993: train_loss/word=0.691 (words=379872, words/sec=6253.98, time=0-00:39:09)   
   Epoch 12.7270: train_loss/word=0.693 (words=394592, words/sec=5961.54, time=0-00:39:11)   
   Epoch 12.7550: train_loss/word=0.701 (words=409864, words/sec=5350.61, time=0-00:39:14)   
   Epoch 12.7827: train_loss/word=0.692 (words=421512, words/sec=6261.44, time=0-00:39:16)   
   Epoch 12.8104: train_loss/word=0.691 (words=434888, words/sec=6080.00, time=0-00:39:18)   
   Epoch 12.8390: train_loss/word=0.689 (words=448776, words/sec=6064.59, time=0-00:39:21)   
   Epoch 12.8668: train_loss/word=0.679 (words=457096, words/sec=6483.48, time=0-00:39:22)   
   Epoch 12.8945: train_loss/word=0.674 (words=467048, words/sec=6231.46, time=0-00:39:24)   
   Epoch 12.9222: train_loss/word=0.674 (words=483880, words/sec=5999.55, time=0-00:39:26)   
   Epoch 12.9508: train_loss/word=0.676 (words=499336, words/sec=6107.53, time=0-00:39:29)   
   Epoch 12.9785: train_loss/word=0.684 (words=518888, words/sec=5903.30, time=0-00:39:32)   
   Epoch 13.0000: train_loss/word=0.685 (words=532616, words/sec=6087.15, time=0-00:39:34)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 13.0000 dev [auxiliary] Loss: 3.376   
     Epoch 13.0000 dev BLEU4: 0.0338664167664, 0.256590/0.054535/0.015959/0.006560 (BP = 0.973446, ratio=0.97, hyp_len=16275, ref_len=16713) (words=29116, words/sec=309.70, time=0-00:41:08)   
   Epoch 13.0286: train_loss/word=0.603 (words=14784, words/sec=5902.69, time=0-00:41:11)   
   Epoch 13.0563: train_loss/word=0.645 (words=35296, words/sec=6063.47, time=0-00:41:14)   
   Epoch 13.0841: train_loss/word=0.593 (words=45792, words/sec=6072.92, time=0-00:41:16)   
   Epoch 13.1118: train_loss/word=0.564 (words=58944, words/sec=6131.89, time=0-00:41:18)   
   Epoch 13.1404: train_loss/word=0.602 (words=76800, words/sec=5905.61, time=0-00:41:21)   
   Epoch 13.1684: train_loss/word=0.570 (words=90696, words/sec=5817.06, time=0-00:41:24)   
   Epoch 13.1961: train_loss/word=0.608 (words=109416, words/sec=5855.94, time=0-00:41:27)   
   Epoch 13.2238: train_loss/word=0.578 (words=119272, words/sec=6208.85, time=0-00:41:28)   
   Epoch 13.2515: train_loss/word=0.603 (words=136840, words/sec=5803.54, time=0-00:41:31)   
   Epoch 13.2801: train_loss/word=0.598 (words=153704, words/sec=6074.69, time=0-00:41:34)   
   Epoch 13.3079: train_loss/word=0.592 (words=168904, words/sec=6208.02, time=0-00:41:37)   
   Epoch 13.3356: train_loss/word=0.609 (words=185288, words/sec=5743.86, time=0-00:41:39)   
   Epoch 13.3633: train_loss/word=0.621 (words=203048, words/sec=5906.04, time=0-00:41:43)   
   Epoch 13.3919: train_loss/word=0.624 (words=220104, words/sec=6006.99, time=0-00:41:45)   
   Epoch 13.4196: train_loss/word=0.628 (words=233768, words/sec=5806.56, time=0-00:41:48)   
   Epoch 13.4474: train_loss/word=0.624 (words=246088, words/sec=6048.72, time=0-00:41:50)   
   Epoch 13.4751: train_loss/word=0.611 (words=256936, words/sec=6224.62, time=0-00:41:51)   
   Epoch 13.5037: train_loss/word=0.607 (words=269384, words/sec=6101.85, time=0-00:41:54)   
   Epoch 13.5314: train_loss/word=0.615 (words=285160, words/sec=5740.00, time=0-00:41:56)   
   Epoch 13.5591: train_loss/word=0.611 (words=301384, words/sec=6073.42, time=0-00:41:59)   
   Epoch 13.5869: train_loss/word=0.607 (words=314888, words/sec=6025.83, time=0-00:42:01)   
   Epoch 13.6155: train_loss/word=0.601 (words=331976, words/sec=6264.98, time=0-00:42:04)   
   Epoch 13.6432: train_loss/word=0.610 (words=350280, words/sec=5871.14, time=0-00:42:07)   
   Epoch 13.6709: train_loss/word=0.605 (words=361992, words/sec=6158.50, time=0-00:42:09)   
   Epoch 13.6986: train_loss/word=0.597 (words=372200, words/sec=6289.35, time=0-00:42:11)   
   Epoch 13.7273: train_loss/word=0.594 (words=386600, words/sec=6044.12, time=0-00:42:13)   
   Epoch 13.7550: train_loss/word=0.605 (words=404360, words/sec=5664.55, time=0-00:42:16)   
   Epoch 13.7827: train_loss/word=0.602 (words=418440, words/sec=6254.99, time=0-00:42:18)   
   Epoch 13.8104: train_loss/word=0.615 (words=437992, words/sec=5837.49, time=0-00:42:22)   
   Epoch 13.8390: train_loss/word=0.621 (words=453864, words/sec=5797.88, time=0-00:42:24)   
   Epoch 13.8668: train_loss/word=0.614 (words=465992, words/sec=6330.23, time=0-00:42:26)   
   Epoch 13.8945: train_loss/word=0.615 (words=480008, words/sec=6005.20, time=0-00:42:29)   
   Epoch 13.9222: train_loss/word=0.610 (words=490216, words/sec=6173.15, time=0-00:42:30)   
   Epoch 13.9508: train_loss/word=0.611 (words=504104, words/sec=5890.87, time=0-00:42:33)   
   Epoch 13.9785: train_loss/word=0.616 (words=519752, words/sec=5934.12, time=0-00:42:35)   
   Epoch 14.0000: train_loss/word=0.618 (words=532616, words/sec=5929.95, time=0-00:42:37)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 14.0000 dev [auxiliary] Loss: 3.430   
     Epoch 14.0000 dev BLEU4: 0.0331943729021, 0.259505/0.054275/0.016242/0.006627 (BP = 0.945999, ratio=0.95, hyp_len=15834, ref_len=16713) (words=29116, words/sec=325.39, time=0-00:44:07)   
   Epoch 14.0280: train_loss/word=0.419 (words=14728, words/sec=5586.27, time=0-00:44:10)   
   Epoch 14.0566: train_loss/word=0.505 (words=29192, words/sec=5936.71, time=0-00:44:12)   
   Epoch 14.0843: train_loss/word=0.505 (words=43624, words/sec=6157.46, time=0-00:44:14)   
   Epoch 14.1120: train_loss/word=0.467 (words=57064, words/sec=6288.58, time=0-00:44:17)   
   Epoch 14.1398: train_loss/word=0.510 (words=75720, words/sec=5994.21, time=0-00:44:20)   
   Epoch 14.1684: train_loss/word=0.496 (words=87016, words/sec=6009.42, time=0-00:44:21)   
   Epoch 14.1961: train_loss/word=0.499 (words=104584, words/sec=5972.09, time=0-00:44:24)   
   Epoch 14.2238: train_loss/word=0.487 (words=118792, words/sec=6137.88, time=0-00:44:27)   
   Epoch 14.2515: train_loss/word=0.501 (words=134408, words/sec=6028.59, time=0-00:44:29)   
   Epoch 14.2801: train_loss/word=0.514 (words=149832, words/sec=5739.97, time=0-00:44:32)   
   Epoch 14.3079: train_loss/word=0.507 (words=164584, words/sec=6127.09, time=0-00:44:34)   
   Epoch 14.3356: train_loss/word=0.524 (words=183048, words/sec=5920.77, time=0-00:44:38)   
   Epoch 14.3633: train_loss/word=0.535 (words=200328, words/sec=5847.53, time=0-00:44:41)   
   Epoch 14.3919: train_loss/word=0.531 (words=215016, words/sec=6046.14, time=0-00:44:43)   
   Epoch 14.4196: train_loss/word=0.530 (words=228584, words/sec=5980.94, time=0-00:44:45)   
   Epoch 14.4474: train_loss/word=0.526 (words=240392, words/sec=5955.66, time=0-00:44:47)   
   Epoch 14.4751: train_loss/word=0.523 (words=253384, words/sec=5998.08, time=0-00:44:49)   
   Epoch 14.5037: train_loss/word=0.529 (words=265768, words/sec=5766.69, time=0-00:44:52)   
   Epoch 14.5314: train_loss/word=0.544 (words=283432, words/sec=5741.62, time=0-00:44:55)   
   Epoch 14.5591: train_loss/word=0.550 (words=302824, words/sec=5938.00, time=0-00:44:58)   
   Epoch 14.5869: train_loss/word=0.556 (words=318120, words/sec=5880.41, time=0-00:45:00)   
   Epoch 14.6155: train_loss/word=0.552 (words=332648, words/sec=6052.79, time=0-00:45:03)   
   Epoch 14.6432: train_loss/word=0.552 (words=346600, words/sec=6052.35, time=0-00:45:05)   
   Epoch 14.6709: train_loss/word=0.548 (words=359624, words/sec=6109.87, time=0-00:45:07)   
   Epoch 14.6986: train_loss/word=0.554 (words=374344, words/sec=5646.61, time=0-00:45:10)   
   Epoch 14.7273: train_loss/word=0.557 (words=390920, words/sec=6002.67, time=0-00:45:13)   
   Epoch 14.7550: train_loss/word=0.552 (words=404200, words/sec=6174.93, time=0-00:45:15)   
   Epoch 14.7827: train_loss/word=0.560 (words=420552, words/sec=5929.50, time=0-00:45:18)   
   Epoch 14.8104: train_loss/word=0.561 (words=436776, words/sec=6087.07, time=0-00:45:20)   
   Epoch 14.8390: train_loss/word=0.565 (words=451880, words/sec=6019.25, time=0-00:45:23)   
   Epoch 14.8668: train_loss/word=0.563 (words=464360, words/sec=5988.76, time=0-00:45:25)   
   Epoch 14.8945: train_loss/word=0.559 (words=476712, words/sec=6039.86, time=0-00:45:27)   
   Epoch 14.9222: train_loss/word=0.557 (words=489960, words/sec=6059.56, time=0-00:45:29)   
   Epoch 14.9508: train_loss/word=0.560 (words=509096, words/sec=5983.85, time=0-00:45:32)   
   Epoch 14.9785: train_loss/word=0.558 (words=523560, words/sec=6153.72, time=0-00:45:35)   
   Epoch 15.0000: train_loss/word=0.559 (words=532616, words/sec=6063.94, time=0-00:45:36)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 15.0000 dev [auxiliary] Loss: 3.519   
     Epoch 15.0000 dev BLEU4: 0.0354045522704, 0.256265/0.053782/0.017464/0.008131 (BP = 0.946567, ratio=0.95, hyp_len=15843, ref_len=16713) (words=29116, words/sec=323.23, time=0-00:47:06)   
     new learning rate: 0.000500000023749   
   Epoch 15.0286: train_loss/word=0.285 (words=14080, words/sec=6145.91, time=0-00:47:08)   
   Epoch 15.0563: train_loss/word=0.419 (words=31872, words/sec=5901.50, time=0-00:47:11)   
   Epoch 15.0841: train_loss/word=0.442 (words=47904, words/sec=5948.95, time=0-00:47:14)   
   Epoch 15.1118: train_loss/word=0.453 (words=63712, words/sec=5975.19, time=0-00:47:17)   
   Epoch 15.1404: train_loss/word=0.410 (words=74080, words/sec=6410.89, time=0-00:47:18)   
   Epoch 15.1681: train_loss/word=0.423 (words=90912, words/sec=6077.97, time=0-00:47:21)   
   Epoch 15.1958: train_loss/word=0.416 (words=103424, words/sec=6107.48, time=0-00:47:23)   
   Epoch 15.2236: train_loss/word=0.432 (words=120544, words/sec=5873.08, time=0-00:47:26)   
   Epoch 15.2522: train_loss/word=0.427 (words=135776, words/sec=6120.69, time=0-00:47:29)   
   Epoch 15.2801: train_loss/word=0.438 (words=152456, words/sec=5501.50, time=0-00:47:32)   
   Epoch 15.3079: train_loss/word=0.434 (words=166216, words/sec=6087.22, time=0-00:47:34)   
   Epoch 15.3356: train_loss/word=0.422 (words=178280, words/sec=6149.82, time=0-00:47:36)   
   Epoch 15.3633: train_loss/word=0.438 (words=200072, words/sec=5883.73, time=0-00:47:40)   
   Epoch 15.3919: train_loss/word=0.429 (words=212008, words/sec=6232.31, time=0-00:47:42)   
   Epoch 15.4196: train_loss/word=0.420 (words=224104, words/sec=6303.78, time=0-00:47:43)   
   Epoch 15.4474: train_loss/word=0.417 (words=235496, words/sec=6142.53, time=0-00:47:45)   
   Epoch 15.4751: train_loss/word=0.422 (words=253320, words/sec=5946.35, time=0-00:47:48)   
   Epoch 15.5037: train_loss/word=0.420 (words=267016, words/sec=5863.86, time=0-00:47:51)   
   Epoch 15.5314: train_loss/word=0.419 (words=281832, words/sec=5982.29, time=0-00:47:53)   
   Epoch 15.5591: train_loss/word=0.418 (words=295400, words/sec=5917.55, time=0-00:47:55)   
   Epoch 15.5869: train_loss/word=0.413 (words=306664, words/sec=6231.94, time=0-00:47:57)   
   Epoch 15.6155: train_loss/word=0.420 (words=321288, words/sec=5798.67, time=0-00:48:00)   
   Epoch 15.6432: train_loss/word=0.426 (words=337288, words/sec=5822.04, time=0-00:48:02)   
   Epoch 15.6709: train_loss/word=0.416 (words=350504, words/sec=6415.08, time=0-00:48:05)   
   Epoch 15.6986: train_loss/word=0.416 (words=370056, words/sec=6121.02, time=0-00:48:08)   
   Epoch 15.7273: train_loss/word=0.419 (words=387848, words/sec=6005.13, time=0-00:48:11)   
   Epoch 15.7550: train_loss/word=0.423 (words=404968, words/sec=5979.75, time=0-00:48:14)   
   Epoch 15.7827: train_loss/word=0.425 (words=419432, words/sec=5834.51, time=0-00:48:16)   
   Epoch 15.8104: train_loss/word=0.430 (words=435624, words/sec=5737.27, time=0-00:48:19)   
   Epoch 15.8390: train_loss/word=0.427 (words=450408, words/sec=6232.00, time=0-00:48:21)   
   Epoch 15.8668: train_loss/word=0.428 (words=465512, words/sec=5876.64, time=0-00:48:24)   
   Epoch 15.8945: train_loss/word=0.426 (words=477224, words/sec=6099.60, time=0-00:48:26)   
   Epoch 15.9222: train_loss/word=0.424 (words=489736, words/sec=5946.38, time=0-00:48:28)   
   Epoch 15.9508: train_loss/word=0.437 (words=508648, words/sec=5536.33, time=0-00:48:31)   
   Epoch 15.9785: train_loss/word=0.434 (words=519208, words/sec=6067.31, time=0-00:48:33)   
   Epoch 16.0000: train_loss/word=0.436 (words=532616, words/sec=5992.62, time=0-00:48:35)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 16.0000 dev [auxiliary] Loss: 3.484   
     Epoch 16.0000 dev BLEU4: 0.0345964915965, 0.268394/0.058100/0.017869/0.007820 (BP = 0.900464, ratio=0.91, hyp_len=15127, ref_len=16713) (words=29116, words/sec=331.64, time=0-00:50:03)   
     new learning rate: 0.000250000011874   
   Epoch 16.0286: train_loss/word=0.372 (words=15200, words/sec=5929.07, time=0-00:50:06)   
   Epoch 16.0563: train_loss/word=0.367 (words=29088, words/sec=5900.25, time=0-00:50:08)   
   Epoch 16.0841: train_loss/word=0.323 (words=42912, words/sec=6216.63, time=0-00:50:10)   
   Epoch 16.1118: train_loss/word=0.288 (words=52512, words/sec=6191.72, time=0-00:50:12)   
   Epoch 16.1404: train_loss/word=0.329 (words=68192, words/sec=5801.00, time=0-00:50:14)   
   Epoch 16.1681: train_loss/word=0.341 (words=81920, words/sec=5832.13, time=0-00:50:17)   
   Epoch 16.1958: train_loss/word=0.352 (words=100256, words/sec=5861.23, time=0-00:50:20)   
   Epoch 16.2236: train_loss/word=0.333 (words=115264, words/sec=6184.34, time=0-00:50:22)   
   Epoch 16.2522: train_loss/word=0.353 (words=133536, words/sec=5741.46, time=0-00:50:26)   
   Epoch 16.2799: train_loss/word=0.344 (words=147552, words/sec=6042.05, time=0-00:50:28)   
   Epoch 16.3076: train_loss/word=0.340 (words=161568, words/sec=6221.13, time=0-00:50:30)   
   Epoch 16.3353: train_loss/word=0.337 (words=173152, words/sec=6017.23, time=0-00:50:32)   
   Epoch 16.3640: train_loss/word=0.343 (words=188192, words/sec=5949.37, time=0-00:50:35)   
   Epoch 16.3917: train_loss/word=0.335 (words=199392, words/sec=6142.35, time=0-00:50:36)   
   Epoch 16.4194: train_loss/word=0.334 (words=214432, words/sec=6075.55, time=0-00:50:39)   
   Epoch 16.4471: train_loss/word=0.327 (words=226976, words/sec=6279.47, time=0-00:50:41)   
   Epoch 16.4757: train_loss/word=0.346 (words=247552, words/sec=5696.10, time=0-00:50:44)   
   Epoch 16.5035: train_loss/word=0.346 (words=262720, words/sec=6039.32, time=0-00:50:47)   
   Epoch 16.5312: train_loss/word=0.337 (words=274016, words/sec=6253.13, time=0-00:50:49)   
   Epoch 16.5589: train_loss/word=0.332 (words=285952, words/sec=6056.80, time=0-00:50:51)   
   Epoch 16.5875: train_loss/word=0.334 (words=303328, words/sec=6034.08, time=0-00:50:54)   
   Epoch 16.6152: train_loss/word=0.348 (words=320000, words/sec=5600.92, time=0-00:50:57)   
   Epoch 16.6430: train_loss/word=0.350 (words=335808, words/sec=6026.27, time=0-00:50:59)   
   Epoch 16.6707: train_loss/word=0.348 (words=351552, words/sec=6041.61, time=0-00:51:02)   
   Epoch 16.6993: train_loss/word=0.354 (words=370592, words/sec=6001.10, time=0-00:51:05)   
   Epoch 16.7270: train_loss/word=0.350 (words=387808, words/sec=6279.49, time=0-00:51:08)   
   Epoch 16.7547: train_loss/word=0.346 (words=398304, words/sec=6139.54, time=0-00:51:09)   
   Epoch 16.7825: train_loss/word=0.342 (words=413248, words/sec=6136.74, time=0-00:51:12)   
   Epoch 16.8104: train_loss/word=0.346 (words=431080, words/sec=5579.43, time=0-00:51:15)   
   Epoch 16.8390: train_loss/word=0.350 (words=447848, words/sec=5942.98, time=0-00:51:18)   
   Epoch 16.8668: train_loss/word=0.350 (words=461672, words/sec=5925.78, time=0-00:51:20)   
   Epoch 16.8945: train_loss/word=0.347 (words=474920, words/sec=6043.93, time=0-00:51:22)   
   Epoch 16.9222: train_loss/word=0.355 (words=493384, words/sec=5764.76, time=0-00:51:26)   
   Epoch 16.9508: train_loss/word=0.356 (words=507496, words/sec=6046.99, time=0-00:51:28)   
   Epoch 16.9785: train_loss/word=0.356 (words=520328, words/sec=5905.11, time=0-00:51:30)   
   Epoch 17.0000: train_loss/word=0.355 (words=532616, words/sec=6317.49, time=0-00:51:32)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 17.0000 dev [auxiliary] Loss: 3.508   
     Epoch 17.0000 dev BLEU4: 0.0383778183057, 0.261403/0.058407/0.020533/0.009941 (BP = 0.913410, ratio=0.92, hyp_len=15325, ref_len=16713) (words=29116, words/sec=323.78, time=0-00:53:02)   
     new learning rate: 0.000125000005937   
   Epoch 17.0286: train_loss/word=0.337 (words=15712, words/sec=6066.17, time=0-00:53:05)   
   Epoch 17.0563: train_loss/word=0.259 (words=26720, words/sec=6250.66, time=0-00:53:06)   
   Epoch 17.0843: train_loss/word=0.243 (words=40296, words/sec=5698.06, time=0-00:53:09)   
   Epoch 17.1120: train_loss/word=0.289 (words=57928, words/sec=5910.11, time=0-00:53:12)   
   Epoch 17.1398: train_loss/word=0.282 (words=72040, words/sec=6078.06, time=0-00:53:14)   
   Epoch 17.1684: train_loss/word=0.260 (words=83912, words/sec=6291.71, time=0-00:53:16)   
   Epoch 17.1961: train_loss/word=0.279 (words=98472, words/sec=5866.90, time=0-00:53:18)   
   Epoch 17.2238: train_loss/word=0.268 (words=110216, words/sec=6124.21, time=0-00:53:20)   
   Epoch 17.2515: train_loss/word=0.292 (words=130440, words/sec=5822.77, time=0-00:53:24)   
   Epoch 17.2801: train_loss/word=0.312 (words=148424, words/sec=5726.68, time=0-00:53:27)   
   Epoch 17.3079: train_loss/word=0.323 (words=164200, words/sec=5791.90, time=0-00:53:30)   
   Epoch 17.3356: train_loss/word=0.319 (words=177832, words/sec=6065.85, time=0-00:53:32)   
   Epoch 17.3633: train_loss/word=0.319 (words=192104, words/sec=5907.38, time=0-00:53:34)   
   Epoch 17.3919: train_loss/word=0.311 (words=204712, words/sec=6029.52, time=0-00:53:36)   
   Epoch 17.4196: train_loss/word=0.310 (words=222088, words/sec=6047.77, time=0-00:53:39)   
   Epoch 17.4474: train_loss/word=0.300 (words=235240, words/sec=6291.80, time=0-00:53:41)   
   Epoch 17.4751: train_loss/word=0.299 (words=250824, words/sec=6088.67, time=0-00:53:44)   
   Epoch 17.5037: train_loss/word=0.301 (words=266984, words/sec=6101.79, time=0-00:53:47)   
   Epoch 17.5314: train_loss/word=0.304 (words=279592, words/sec=5912.85, time=0-00:53:49)   
   Epoch 17.5591: train_loss/word=0.311 (words=299080, words/sec=5778.10, time=0-00:53:52)   
   Epoch 17.5869: train_loss/word=0.312 (words=314824, words/sec=6038.13, time=0-00:53:55)   
   Epoch 17.6155: train_loss/word=0.317 (words=332136, words/sec=5874.16, time=0-00:53:58)   
   Epoch 17.6432: train_loss/word=0.319 (words=349672, words/sec=5937.25, time=0-00:54:01)   
   Epoch 17.6709: train_loss/word=0.324 (words=366120, words/sec=5820.59, time=0-00:54:03)   
   Epoch 17.6986: train_loss/word=0.324 (words=383080, words/sec=6013.70, time=0-00:54:06)   
   Epoch 17.7273: train_loss/word=0.325 (words=397608, words/sec=5950.49, time=0-00:54:09)   
   Epoch 17.7550: train_loss/word=0.322 (words=411304, words/sec=6174.74, time=0-00:54:11)   
   Epoch 17.7827: train_loss/word=0.324 (words=424936, words/sec=5883.20, time=0-00:54:13)   
   Epoch 17.8104: train_loss/word=0.324 (words=436840, words/sec=6036.99, time=0-00:54:15)   
   Epoch 17.8390: train_loss/word=0.323 (words=455208, words/sec=6010.16, time=0-00:54:18)   
   Epoch 17.8668: train_loss/word=0.325 (words=470056, words/sec=5861.77, time=0-00:54:21)   
   Epoch 17.8945: train_loss/word=0.319 (words=479720, words/sec=6312.69, time=0-00:54:22)   
   Epoch 17.9222: train_loss/word=0.318 (words=490312, words/sec=5835.31, time=0-00:54:24)   
   Epoch 17.9508: train_loss/word=0.317 (words=506600, words/sec=5986.64, time=0-00:54:27)   
   Epoch 17.9785: train_loss/word=0.317 (words=522952, words/sec=6139.66, time=0-00:54:30)   
   Epoch 18.0000: train_loss/word=0.315 (words=532616, words/sec=5951.55, time=0-00:54:31)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 18.0000 dev [auxiliary] Loss: 3.529   
     Epoch 18.0000 dev BLEU4: 0.0389982257777, 0.265242/0.058808/0.020024/0.009900 (BP = 0.929988, ratio=0.93, hyp_len=15582, ref_len=16713) (words=29116, words/sec=320.89, time=0-00:56:02)   
     Early stopping   
   reverting learned weights to best checkpoint..   
   > Evaluating test set   
     initialized PolynomialNormalization({'apply_during_search': True})     
     /projects/tir2/users/xinyiw1/loreili/test.piece.src     
     BLEU4: 0.00288254182928, 0.128781/0.010467/0.000855/0.000141 (BP = 0.806917, ratio=0.82, hyp_len=146093, ref_len=177435)     

Experiment                    | Final Scores                           
-----------------------------------------------------------------------
oromo-seq                     | BLEU4: 0.00288254182928, 0.128781/0.010467/0.000855/0.000141 (BP = 0.806917, ratio=0.82, hyp_len=146093, ref_len=177435)
