Singularity: Invoking an interactive shell within container...

[0m/opt/cudnn-8.0/lib64:/home/xinyiw1/software/dynet-repo/dynet/build/dynet/:/projects/tir1/cuda-8.0.27.1/lib64:/opt/cudnn-5.1/lib64:/opt/cuda-8.0/lib64:/opt/cuda-8.0/lib:/opt/cuda-8.0/lib64/:/home/xinyiw1/gcc-5.2.0/lib64:/home/xinyiw1/boost_1_65_1/lib:/home/xinyiw1/gcc-5.2.0/lib:/opt/cuda-8.0/lib64/:/home/xinyiw1/gcc-5.2.0/lib64:/home/xinyiw1/boost_1_65_1/lib:/home/xinyiw1/gcc-5.2.0/lib:/opt/cuda-8.0/lib64/:/home/xinyiw1/gcc-5.2.0/lib64:/home/xinyiw1/boost_1_65_1/lib:/home/xinyiw1/gcc-5.2.0/lib:/opt/cuda-8.0/lib64/:/home/xinyiw1/gcc-5.2.0/lib64:/home/xinyiw1/boost_1_65_1/lib:/home/xinyiw1/gcc-5.2.0/lib:/opt/openmpi/lib
[dynet] initializing CUDA
Request for 1 GPU ...
[dynet] Device Number: 0
[dynet]   Device name: GeForce GTX 1080 Ti
[dynet]   Memory Clock Rate (KHz): 5505000
[dynet]   Memory Bus Width (bits): 352
[dynet]   Peak Memory Bandwidth (GB/s): 484.44
[dynet]   Memory Free (GB): 11.5421/11.7151
[dynet]
[dynet] Device(s) selected: 0
[dynet] random seed: 1028905461
[dynet] allocating memory: 10000MB
[dynet] memory allocation done.
=> Running oromo-seq
   > Preprocessing   
   > Training   
   initialized BilingualTrainingCorpus({'train_src': '/projects/tir2/users/xinyiw1/loreili/train.piece.src', 'dev_trg': '/projects/tir2/users/xinyiw1/loreili/dev.piece.trg', 'dev_ref_file': '/projects/tir2/users/xinyiw1/loreili/dev.clean.trg', 'dev_src': '/projects/tir2/users/xinyiw1/loreili/dev.piece.src', 'train_trg': '/projects/tir2/users/xinyiw1/loreili/train.piece.trg'})   
   initialized PlainTextReader({})   
   initialized PlainTextReader({})   
   initialized BilingualCorpusParser({'trg_reader': <xnmt.input.PlainTextReader object at 0x7f2104819bd0>, 'src_reader': <xnmt.input.PlainTextReader object at 0x7f2104819d90>})   
   /projects/tir2/users/xinyiw1/loreili/train.piece.src   
   /projects/tir2/users/xinyiw1/loreili/train.piece.trg   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.trg   
   initialized SimpleWordEmbedder({'vocab_size': 8074, 'yaml_context': <xnmt.model_context.ModelContext object at 0x7f2104819a50>})   
   initialized LSTMSeqTransducer({'layers': 1, 'yaml_context': <xnmt.model_context.ModelContext object at 0x7f2104819a50>})   
   initialized StandardAttender({'yaml_context': <xnmt.model_context.ModelContext object at 0x7f2104819a50>})   
   initialized SimpleWordEmbedder({'vocab_size': 8067, 'yaml_context': <xnmt.model_context.ModelContext object at 0x7f2104819a50>})   
   initialized CopyBridge({'yaml_context': <xnmt.model_context.ModelContext object at 0x7f2104819a50>, 'dec_layers': 1})   
   initialized MlpSoftmaxDecoder({'layers': 1, 'bridge': <xnmt.decoder.CopyBridge object at 0x7f2102393190>, 'yaml_context': <xnmt.model_context.ModelContext object at 0x7f2104819a50>, 'mlp_hidden_dim': 512, 'vocab_size': 8067})   
   initialized DefaultTranslator({'src_embedder': <xnmt.embedder.SimpleWordEmbedder object at 0x7f2102388f90>, 'decoder': <xnmt.decoder.MlpSoftmaxDecoder object at 0x7f2102393150>, 'trg_embedder': <xnmt.embedder.SimpleWordEmbedder object at 0x7f2102393110>, 'attender': <xnmt.attender.StandardAttender object at 0x7f21023930d0>, 'encoder': <xnmt.lstm.LSTMSeqTransducer object at 0x7f2102388fd0>})   
   initialized SrcBatcher({'batch_size': 32})   
   Epoch 0.0286: train_loss/word=4.600 (words=15712, words/sec=5946.32, time=0-00:00:02)   
   Epoch 0.0566: train_loss/word=4.428 (words=35400, words/sec=5612.47, time=0-00:00:06)   
   Epoch 0.0843: train_loss/word=4.387 (words=50920, words/sec=6076.11, time=0-00:00:08)   
   Epoch 0.1120: train_loss/word=4.172 (words=62536, words/sec=6202.48, time=0-00:00:10)   
   Epoch 0.1398: train_loss/word=4.072 (words=76584, words/sec=6075.08, time=0-00:00:12)   
   Epoch 0.1684: train_loss/word=3.973 (words=90888, words/sec=5705.30, time=0-00:00:15)   
   Epoch 0.1961: train_loss/word=4.083 (words=104744, words/sec=5835.78, time=0-00:00:17)   
   Epoch 0.2238: train_loss/word=4.055 (words=123080, words/sec=5659.96, time=0-00:00:21)   
   Epoch 0.2515: train_loss/word=3.944 (words=134568, words/sec=6164.54, time=0-00:00:22)   
   Epoch 0.2801: train_loss/word=3.898 (words=149640, words/sec=5971.23, time=0-00:00:25)   
   Epoch 0.3079: train_loss/word=3.853 (words=163400, words/sec=5964.68, time=0-00:00:27)   
   Epoch 0.3356: train_loss/word=3.791 (words=177896, words/sec=5957.05, time=0-00:00:30)   
   Epoch 0.3633: train_loss/word=3.755 (words=190504, words/sec=5935.15, time=0-00:00:32)   
   Epoch 0.3919: train_loss/word=3.706 (words=205960, words/sec=6062.08, time=0-00:00:34)   
   Epoch 0.4196: train_loss/word=3.721 (words=222696, words/sec=5623.78, time=0-00:00:37)   
   Epoch 0.4474: train_loss/word=3.702 (words=234056, words/sec=5925.04, time=0-00:00:39)   
   Epoch 0.4751: train_loss/word=3.682 (words=248968, words/sec=6037.97, time=0-00:00:42)   
   Epoch 0.5037: train_loss/word=3.653 (words=263752, words/sec=6044.91, time=0-00:00:44)   
   Epoch 0.5314: train_loss/word=3.634 (words=280712, words/sec=6017.06, time=0-00:00:47)   
   Epoch 0.5591: train_loss/word=3.628 (words=298984, words/sec=6072.30, time=0-00:00:50)   
   Epoch 0.5869: train_loss/word=3.607 (words=312104, words/sec=5903.68, time=0-00:00:52)   
   Epoch 0.6155: train_loss/word=3.583 (words=323656, words/sec=5840.32, time=0-00:00:54)   
   Epoch 0.6432: train_loss/word=3.550 (words=335688, words/sec=6074.96, time=0-00:00:56)   
   Epoch 0.6709: train_loss/word=3.535 (words=351144, words/sec=5828.61, time=0-00:00:59)   
   Epoch 0.6986: train_loss/word=3.525 (words=367304, words/sec=5785.98, time=0-00:01:02)   
   Epoch 0.7273: train_loss/word=3.503 (words=381320, words/sec=5955.56, time=0-00:01:04)   
   Epoch 0.7550: train_loss/word=3.488 (words=398056, words/sec=5722.66, time=0-00:01:07)   
   Epoch 0.7827: train_loss/word=3.463 (words=413000, words/sec=6087.52, time=0-00:01:09)   
   Epoch 0.8104: train_loss/word=3.431 (words=425960, words/sec=6218.74, time=0-00:01:11)   
   Epoch 0.8390: train_loss/word=3.416 (words=437288, words/sec=5812.38, time=0-00:01:13)   
   Epoch 0.8668: train_loss/word=3.395 (words=451848, words/sec=5946.97, time=0-00:01:16)   
   Epoch 0.8945: train_loss/word=3.382 (words=468040, words/sec=6091.14, time=0-00:01:18)   
   Epoch 0.9222: train_loss/word=3.377 (words=486088, words/sec=5984.07, time=0-00:01:21)   
   Epoch 0.9508: train_loss/word=3.370 (words=507176, words/sec=5844.24, time=0-00:01:25)   
   Epoch 0.9785: train_loss/word=3.353 (words=520168, words/sec=5989.08, time=0-00:01:27)   
   Epoch 1.0000: train_loss/word=3.344 (words=531912, words/sec=5929.41, time=0-00:01:29)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 1.0000 dev [auxiliary] Loss: 4.140   
     Epoch 1.0000 dev BLEU4: 0.0130216774427, 0.110813/0.017117/0.005488/0.002762 (BP = 1.000000, ratio=1.07, hyp_len=17886, ref_len=16713) (words=29308, words/sec=158.09, time=0-00:04:35)   
     Epoch 1.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 1.0286: train_loss/word=2.704 (words=13696, words/sec=609.99, time=0-00:04:57)   
   Epoch 1.0563: train_loss/word=2.784 (words=29280, words/sec=5847.92, time=0-00:05:00)   
   Epoch 1.0841: train_loss/word=2.712 (words=41632, words/sec=5954.02, time=0-00:05:02)   
   Epoch 1.1118: train_loss/word=2.786 (words=57120, words/sec=5714.55, time=0-00:05:05)   
   Epoch 1.1404: train_loss/word=2.857 (words=77120, words/sec=5779.84, time=0-00:05:08)   
   Epoch 1.1681: train_loss/word=2.857 (words=92128, words/sec=5786.42, time=0-00:05:11)   
   Epoch 1.1958: train_loss/word=2.804 (words=103680, words/sec=5977.63, time=0-00:05:12)   
   Epoch 1.2236: train_loss/word=2.790 (words=115168, words/sec=5938.69, time=0-00:05:14)   
   Epoch 1.2522: train_loss/word=2.747 (words=126464, words/sec=6061.68, time=0-00:05:16)   
   Epoch 1.2799: train_loss/word=2.747 (words=143040, words/sec=6007.28, time=0-00:05:19)   
   Epoch 1.3076: train_loss/word=2.728 (words=155616, words/sec=6041.85, time=0-00:05:21)   
   Epoch 1.3353: train_loss/word=2.736 (words=170528, words/sec=5382.29, time=0-00:05:24)   
   Epoch 1.3640: train_loss/word=2.717 (words=183776, words/sec=5884.71, time=0-00:05:26)   
   Epoch 1.3917: train_loss/word=2.700 (words=197248, words/sec=5960.78, time=0-00:05:28)   
   Epoch 1.4194: train_loss/word=2.680 (words=211584, words/sec=5948.82, time=0-00:05:31)   
   Epoch 1.4471: train_loss/word=2.666 (words=222592, words/sec=5775.91, time=0-00:05:33)   
   Epoch 1.4757: train_loss/word=2.663 (words=235648, words/sec=5701.11, time=0-00:05:35)   
   Epoch 1.5035: train_loss/word=2.643 (words=246560, words/sec=5870.88, time=0-00:05:37)   
   Epoch 1.5312: train_loss/word=2.639 (words=261664, words/sec=5650.11, time=0-00:05:40)   
   Epoch 1.5589: train_loss/word=2.636 (words=276096, words/sec=5625.86, time=0-00:05:42)   
   Epoch 1.5875: train_loss/word=2.644 (words=291552, words/sec=5682.47, time=0-00:05:45)   
   Epoch 1.6152: train_loss/word=2.644 (words=307072, words/sec=5947.10, time=0-00:05:47)   
   Epoch 1.6430: train_loss/word=2.652 (words=324960, words/sec=5922.53, time=0-00:05:50)   
   Epoch 1.6707: train_loss/word=2.645 (words=338816, words/sec=6069.86, time=0-00:05:53)   
   Epoch 1.6993: train_loss/word=2.625 (words=351488, words/sec=6209.48, time=0-00:05:55)   
   Epoch 1.7270: train_loss/word=2.621 (words=364672, words/sec=5863.63, time=0-00:05:57)   
   Epoch 1.7547: train_loss/word=2.618 (words=379968, words/sec=5942.38, time=0-00:06:00)   
   Epoch 1.7825: train_loss/word=2.613 (words=395456, words/sec=5982.41, time=0-00:06:02)   
   Epoch 1.8104: train_loss/word=2.611 (words=411080, words/sec=5150.18, time=0-00:06:05)   
   Epoch 1.8390: train_loss/word=2.622 (words=433224, words/sec=5767.56, time=0-00:06:09)   
   Epoch 1.8668: train_loss/word=2.619 (words=451400, words/sec=6094.11, time=0-00:06:12)   
   Epoch 1.8945: train_loss/word=2.635 (words=474920, words/sec=5626.19, time=0-00:06:16)   
   Epoch 1.9222: train_loss/word=2.627 (words=490920, words/sec=5943.58, time=0-00:06:19)   
   Epoch 1.9508: train_loss/word=2.630 (words=507400, words/sec=5695.35, time=0-00:06:22)   
   Epoch 1.9785: train_loss/word=2.630 (words=522184, words/sec=5763.48, time=0-00:06:24)   
   Epoch 2.0000: train_loss/word=2.618 (words=531912, words/sec=6263.96, time=0-00:06:26)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 2.0000 dev [auxiliary] Loss: 3.649   
     Epoch 2.0000 dev BLEU4: 0.0225821874952, 0.174236/0.031576/0.009800/0.004823 (BP = 1.000000, ratio=1.13, hyp_len=18957, ref_len=16713) (words=29308, words/sec=174.13, time=0-00:09:14)   
     Epoch 2.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 2.0286: train_loss/word=2.430 (words=15328, words/sec=677.96, time=0-00:09:37)   
   Epoch 2.0563: train_loss/word=2.530 (words=31296, words/sec=5858.38, time=0-00:09:40)   
   Epoch 2.0841: train_loss/word=2.534 (words=49440, words/sec=5993.31, time=0-00:09:43)   
   Epoch 2.1118: train_loss/word=2.472 (words=64480, words/sec=6091.71, time=0-00:09:45)   
   Epoch 2.1404: train_loss/word=2.397 (words=80448, words/sec=6204.38, time=0-00:09:48)   
   Epoch 2.1681: train_loss/word=2.367 (words=91520, words/sec=5711.38, time=0-00:09:50)   
   Epoch 2.1958: train_loss/word=2.350 (words=106784, words/sec=5739.21, time=0-00:09:52)   
   Epoch 2.2236: train_loss/word=2.336 (words=122432, words/sec=5887.69, time=0-00:09:55)   
   Epoch 2.2522: train_loss/word=2.307 (words=136288, words/sec=5920.69, time=0-00:09:57)   
   Epoch 2.2799: train_loss/word=2.293 (words=150048, words/sec=6016.52, time=0-00:10:00)   
   Epoch 2.3076: train_loss/word=2.317 (words=167072, words/sec=5794.34, time=0-00:10:02)   
   Epoch 2.3353: train_loss/word=2.333 (words=184256, words/sec=5772.79, time=0-00:10:05)   
   Epoch 2.3640: train_loss/word=2.335 (words=200000, words/sec=5730.59, time=0-00:10:08)   
   Epoch 2.3917: train_loss/word=2.311 (words=210848, words/sec=6047.95, time=0-00:10:10)   
   Epoch 2.4194: train_loss/word=2.320 (words=228000, words/sec=5956.30, time=0-00:10:13)   
   Epoch 2.4474: train_loss/word=2.350 (words=247976, words/sec=5508.94, time=0-00:10:17)   
   Epoch 2.4751: train_loss/word=2.360 (words=262824, words/sec=5768.72, time=0-00:10:19)   
   Epoch 2.5037: train_loss/word=2.349 (words=274376, words/sec=6028.17, time=0-00:10:21)   
   Epoch 2.5314: train_loss/word=2.336 (words=285480, words/sec=6002.64, time=0-00:10:23)   
   Epoch 2.5591: train_loss/word=2.330 (words=299368, words/sec=6093.90, time=0-00:10:25)   
   Epoch 2.5869: train_loss/word=2.310 (words=312712, words/sec=6232.32, time=0-00:10:27)   
   Epoch 2.6155: train_loss/word=2.294 (words=326088, words/sec=6079.90, time=0-00:10:29)   
   Epoch 2.6432: train_loss/word=2.286 (words=338888, words/sec=5855.02, time=0-00:10:32)   
   Epoch 2.6709: train_loss/word=2.277 (words=351528, words/sec=5945.40, time=0-00:10:34)   
   Epoch 2.6986: train_loss/word=2.278 (words=366984, words/sec=5935.14, time=0-00:10:36)   
   Epoch 2.7273: train_loss/word=2.280 (words=385256, words/sec=5942.28, time=0-00:10:39)   
   Epoch 2.7550: train_loss/word=2.267 (words=396488, words/sec=5967.96, time=0-00:10:41)   
   Epoch 2.7827: train_loss/word=2.263 (words=410056, words/sec=5867.48, time=0-00:10:44)   
   Epoch 2.8104: train_loss/word=2.262 (words=428104, words/sec=5934.40, time=0-00:10:47)   
   Epoch 2.8390: train_loss/word=2.270 (words=446568, words/sec=5677.87, time=0-00:10:50)   
   Epoch 2.8668: train_loss/word=2.261 (words=462120, words/sec=6046.48, time=0-00:10:53)   
   Epoch 2.8945: train_loss/word=2.247 (words=474088, words/sec=6302.06, time=0-00:10:54)   
   Epoch 2.9222: train_loss/word=2.251 (words=489448, words/sec=5839.53, time=0-00:10:57)   
   Epoch 2.9508: train_loss/word=2.251 (words=504616, words/sec=5955.08, time=0-00:11:00)   
   Epoch 2.9785: train_loss/word=2.245 (words=517608, words/sec=6048.00, time=0-00:11:02)   
   Epoch 3.0000: train_loss/word=2.249 (words=531912, words/sec=5772.90, time=0-00:11:04)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 3.0000 dev [auxiliary] Loss: 3.502   
     Epoch 3.0000 dev BLEU4: 0.0160703738367, 0.221606/0.035177/0.006658/0.002724 (BP = 0.828742, ratio=0.84, hyp_len=14070, ref_len=16713) (words=29308, words/sec=223.65, time=0-00:13:15)   
   Epoch 3.0286: train_loss/word=1.826 (words=14272, words/sec=5751.17, time=0-00:13:18)   
   Epoch 3.0563: train_loss/word=2.035 (words=31584, words/sec=5713.91, time=0-00:13:21)   
   Epoch 3.0841: train_loss/word=1.864 (words=43808, words/sec=6172.34, time=0-00:13:23)   
   Epoch 3.1118: train_loss/word=1.854 (words=55680, words/sec=5959.09, time=0-00:13:25)   
   Epoch 3.1404: train_loss/word=1.900 (words=71008, words/sec=6066.55, time=0-00:13:27)   
   Epoch 3.1681: train_loss/word=1.947 (words=88288, words/sec=6082.77, time=0-00:13:30)   
   Epoch 3.1958: train_loss/word=1.943 (words=102784, words/sec=6063.54, time=0-00:13:33)   
   Epoch 3.2236: train_loss/word=1.930 (words=115936, words/sec=6013.46, time=0-00:13:35)   
   Epoch 3.2522: train_loss/word=1.901 (words=128992, words/sec=6211.71, time=0-00:13:37)   
   Epoch 3.2799: train_loss/word=1.947 (words=146208, words/sec=5598.07, time=0-00:13:40)   
   Epoch 3.3076: train_loss/word=1.946 (words=162816, words/sec=5917.50, time=0-00:13:43)   
   Epoch 3.3353: train_loss/word=1.969 (words=181088, words/sec=5785.80, time=0-00:13:46)   
   Epoch 3.3640: train_loss/word=1.966 (words=195712, words/sec=5902.27, time=0-00:13:48)   
   Epoch 3.3917: train_loss/word=1.968 (words=210880, words/sec=5952.06, time=0-00:13:51)   
   Epoch 3.4194: train_loss/word=1.971 (words=223808, words/sec=5517.39, time=0-00:13:53)   
   Epoch 3.4471: train_loss/word=1.965 (words=238304, words/sec=5855.86, time=0-00:13:56)   
   Epoch 3.4757: train_loss/word=1.964 (words=253280, words/sec=5872.19, time=0-00:13:58)   
   Epoch 3.5035: train_loss/word=1.975 (words=267968, words/sec=5647.14, time=0-00:14:01)   
   Epoch 3.5312: train_loss/word=1.973 (words=283072, words/sec=6021.52, time=0-00:14:03)   
   Epoch 3.5589: train_loss/word=1.970 (words=297568, words/sec=6022.34, time=0-00:14:06)   
   Epoch 3.5875: train_loss/word=1.960 (words=311360, words/sec=6219.45, time=0-00:14:08)   
   Epoch 3.6152: train_loss/word=1.960 (words=327104, words/sec=6218.85, time=0-00:14:10)   
   Epoch 3.6430: train_loss/word=1.947 (words=337120, words/sec=6021.75, time=0-00:14:12)   
   Epoch 3.6707: train_loss/word=1.939 (words=351296, words/sec=6153.19, time=0-00:14:14)   
   Epoch 3.6993: train_loss/word=1.941 (words=368032, words/sec=5919.53, time=0-00:14:17)   
   Epoch 3.7270: train_loss/word=1.940 (words=381824, words/sec=5841.54, time=0-00:14:20)   
   Epoch 3.7547: train_loss/word=1.946 (words=399424, words/sec=5932.68, time=0-00:14:23)   
   Epoch 3.7825: train_loss/word=1.940 (words=413376, words/sec=5861.89, time=0-00:14:25)   
   Epoch 3.8111: train_loss/word=1.933 (words=428224, words/sec=6054.13, time=0-00:14:27)   
   Epoch 3.8388: train_loss/word=1.938 (words=445152, words/sec=5955.54, time=0-00:14:30)   
   Epoch 3.8665: train_loss/word=1.937 (words=457824, words/sec=5707.81, time=0-00:14:33)   
   Epoch 3.8945: train_loss/word=1.946 (words=475368, words/sec=5540.01, time=0-00:14:36)   
   Epoch 3.9222: train_loss/word=1.946 (words=489032, words/sec=6020.86, time=0-00:14:38)   
   Epoch 3.9508: train_loss/word=1.941 (words=502312, words/sec=6064.03, time=0-00:14:40)   
   Epoch 3.9785: train_loss/word=1.934 (words=518024, words/sec=6246.90, time=0-00:14:43)   
   Epoch 4.0000: train_loss/word=1.942 (words=531912, words/sec=5740.89, time=0-00:14:45)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 4.0000 dev [auxiliary] Loss: 3.285   
     Epoch 4.0000 dev BLEU4: 0.0316047423439, 0.215208/0.045132/0.014325/0.007171 (BP = 1.000000, ratio=1.04, hyp_len=17425, ref_len=16713) (words=29308, words/sec=176.11, time=0-00:17:31)   
     Epoch 4.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 4.0286: train_loss/word=1.386 (words=13664, words/sec=634.87, time=0-00:17:53)   
   Epoch 4.0563: train_loss/word=1.544 (words=29024, words/sec=5990.73, time=0-00:17:56)   
   Epoch 4.0841: train_loss/word=1.506 (words=42080, words/sec=5916.68, time=0-00:17:58)   
   Epoch 4.1118: train_loss/word=1.574 (words=56128, words/sec=5799.44, time=0-00:18:00)   
   Epoch 4.1404: train_loss/word=1.570 (words=71040, words/sec=6146.69, time=0-00:18:03)   
   Epoch 4.1681: train_loss/word=1.611 (words=86528, words/sec=5803.95, time=0-00:18:05)   
   Epoch 4.1958: train_loss/word=1.587 (words=99904, words/sec=6036.61, time=0-00:18:08)   
   Epoch 4.2236: train_loss/word=1.638 (words=116096, words/sec=5614.80, time=0-00:18:10)   
   Epoch 4.2522: train_loss/word=1.610 (words=129440, words/sec=6111.03, time=0-00:18:13)   
   Epoch 4.2799: train_loss/word=1.624 (words=146048, words/sec=5991.10, time=0-00:18:15)   
   Epoch 4.3076: train_loss/word=1.616 (words=160224, words/sec=5890.56, time=0-00:18:18)   
   Epoch 4.3353: train_loss/word=1.599 (words=171744, words/sec=5839.96, time=0-00:18:20)   
   Epoch 4.3640: train_loss/word=1.578 (words=182816, words/sec=5859.90, time=0-00:18:22)   
   Epoch 4.3917: train_loss/word=1.596 (words=198016, words/sec=5826.53, time=0-00:18:24)   
   Epoch 4.4194: train_loss/word=1.635 (words=216608, words/sec=5661.26, time=0-00:18:28)   
   Epoch 4.4471: train_loss/word=1.631 (words=229984, words/sec=6055.51, time=0-00:18:30)   
   Epoch 4.4757: train_loss/word=1.654 (words=248704, words/sec=6043.64, time=0-00:18:33)   
   Epoch 4.5035: train_loss/word=1.652 (words=262720, words/sec=5973.56, time=0-00:18:35)   
   Epoch 4.5312: train_loss/word=1.659 (words=279104, words/sec=6029.29, time=0-00:18:38)   
   Epoch 4.5589: train_loss/word=1.648 (words=292512, words/sec=6214.13, time=0-00:18:40)   
   Epoch 4.5875: train_loss/word=1.653 (words=308992, words/sec=5974.16, time=0-00:18:43)   
   Epoch 4.6152: train_loss/word=1.646 (words=322400, words/sec=5849.35, time=0-00:18:45)   
   Epoch 4.6430: train_loss/word=1.640 (words=335168, words/sec=5806.22, time=0-00:18:47)   
   Epoch 4.6707: train_loss/word=1.646 (words=352096, words/sec=5883.95, time=0-00:18:50)   
   Epoch 4.6993: train_loss/word=1.671 (words=374592, words/sec=5835.02, time=0-00:18:54)   
   Epoch 4.7270: train_loss/word=1.670 (words=386848, words/sec=5704.26, time=0-00:18:56)   
   Epoch 4.7547: train_loss/word=1.672 (words=403360, words/sec=5861.67, time=0-00:18:59)   
   Epoch 4.7825: train_loss/word=1.664 (words=414048, words/sec=5818.14, time=0-00:19:01)   
   Epoch 4.8111: train_loss/word=1.656 (words=426976, words/sec=5954.22, time=0-00:19:03)   
   Epoch 4.8388: train_loss/word=1.647 (words=437984, words/sec=5733.71, time=0-00:19:05)   
   Epoch 4.8665: train_loss/word=1.656 (words=455296, words/sec=5959.39, time=0-00:19:08)   
   Epoch 4.8945: train_loss/word=1.663 (words=473096, words/sec=5558.21, time=0-00:19:11)   
   Epoch 4.9222: train_loss/word=1.661 (words=488552, words/sec=6205.85, time=0-00:19:14)   
   Epoch 4.9508: train_loss/word=1.661 (words=502216, words/sec=5857.63, time=0-00:19:16)   
   Epoch 4.9785: train_loss/word=1.666 (words=520040, words/sec=6084.67, time=0-00:19:19)   
   Epoch 5.0000: train_loss/word=1.669 (words=531912, words/sec=5869.57, time=0-00:19:21)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 5.0000 dev [auxiliary] Loss: 3.201   
     Epoch 5.0000 dev BLEU4: 0.0341337106943, 0.223875/0.051509/0.016804/0.007006 (BP = 1.000000, ratio=1.08, hyp_len=18086, ref_len=16713) (words=29308, words/sec=184.27, time=0-00:22:00)   
     Epoch 5.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 5.0286: train_loss/word=1.373 (words=14080, words/sec=643.81, time=0-00:22:22)   
   Epoch 5.0563: train_loss/word=1.494 (words=32384, words/sec=5849.70, time=0-00:22:25)   
   Epoch 5.0841: train_loss/word=1.399 (words=44896, words/sec=6087.76, time=0-00:22:27)   
   Epoch 5.1118: train_loss/word=1.410 (words=59712, words/sec=5989.74, time=0-00:22:29)   
   Epoch 5.1404: train_loss/word=1.479 (words=76640, words/sec=5805.60, time=0-00:22:32)   
   Epoch 5.1681: train_loss/word=1.404 (words=86208, words/sec=5844.44, time=0-00:22:34)   
   Epoch 5.1958: train_loss/word=1.415 (words=102336, words/sec=5963.96, time=0-00:22:37)   
   Epoch 5.2236: train_loss/word=1.442 (words=117120, words/sec=5602.39, time=0-00:22:39)   
   Epoch 5.2522: train_loss/word=1.449 (words=135488, words/sec=6068.94, time=0-00:22:42)   
   Epoch 5.2799: train_loss/word=1.418 (words=146496, words/sec=6032.13, time=0-00:22:44)   
   Epoch 5.3076: train_loss/word=1.403 (words=158080, words/sec=5853.64, time=0-00:22:46)   
   Epoch 5.3353: train_loss/word=1.400 (words=171008, words/sec=5738.91, time=0-00:22:48)   
   Epoch 5.3640: train_loss/word=1.406 (words=187808, words/sec=5831.58, time=0-00:22:51)   
   Epoch 5.3917: train_loss/word=1.390 (words=200032, words/sec=5927.21, time=0-00:22:53)   
   Epoch 5.4194: train_loss/word=1.376 (words=211776, words/sec=5904.34, time=0-00:22:55)   
   Epoch 5.4471: train_loss/word=1.398 (words=229792, words/sec=6057.41, time=0-00:22:58)   
   Epoch 5.4757: train_loss/word=1.406 (words=246528, words/sec=5991.97, time=0-00:23:01)   
   Epoch 5.5035: train_loss/word=1.401 (words=260512, words/sec=6129.30, time=0-00:23:03)   
   Epoch 5.5312: train_loss/word=1.408 (words=276416, words/sec=5949.82, time=0-00:23:06)   
   Epoch 5.5589: train_loss/word=1.413 (words=292832, words/sec=6013.98, time=0-00:23:09)   
   Epoch 5.5875: train_loss/word=1.410 (words=308544, words/sec=5987.80, time=0-00:23:11)   
   Epoch 5.6152: train_loss/word=1.421 (words=324832, words/sec=5811.29, time=0-00:23:14)   
   Epoch 5.6430: train_loss/word=1.419 (words=338080, words/sec=5746.25, time=0-00:23:16)   
   Epoch 5.6707: train_loss/word=1.418 (words=353504, words/sec=5990.36, time=0-00:23:19)   
   Epoch 5.6993: train_loss/word=1.427 (words=369824, words/sec=5770.67, time=0-00:23:22)   
   Epoch 5.7270: train_loss/word=1.418 (words=381792, words/sec=5955.35, time=0-00:23:24)   
   Epoch 5.7547: train_loss/word=1.414 (words=393568, words/sec=5673.13, time=0-00:23:26)   
   Epoch 5.7825: train_loss/word=1.406 (words=407552, words/sec=6066.50, time=0-00:23:28)   
   Epoch 5.8111: train_loss/word=1.399 (words=420608, words/sec=5984.83, time=0-00:23:30)   
   Epoch 5.8388: train_loss/word=1.407 (words=439424, words/sec=6104.49, time=0-00:23:34)   
   Epoch 5.8665: train_loss/word=1.419 (words=456544, words/sec=5830.30, time=0-00:23:36)   
   Epoch 5.8942: train_loss/word=1.417 (words=470656, words/sec=6113.41, time=0-00:23:39)   
   Epoch 5.9228: train_loss/word=1.423 (words=487552, words/sec=5878.84, time=0-00:23:42)   
   Epoch 5.9506: train_loss/word=1.433 (words=505568, words/sec=5944.83, time=0-00:23:45)   
   Epoch 5.9783: train_loss/word=1.435 (words=518112, words/sec=5870.79, time=0-00:23:47)   
   Epoch 6.0000: train_loss/word=1.441 (words=531912, words/sec=5338.52, time=0-00:23:49)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 6.0000 dev [auxiliary] Loss: 3.164   
     Epoch 6.0000 dev BLEU4: 0.0461961773702, 0.248200/0.067012/0.025451/0.012490 (BP = 0.963386, ratio=0.96, hyp_len=16112, ref_len=16713) (words=29308, words/sec=177.57, time=0-00:26:34)   
     Epoch 6.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 6.0286: train_loss/word=1.568 (words=21696, words/sec=940.84, time=0-00:26:58)   
   Epoch 6.0563: train_loss/word=1.399 (words=36704, words/sec=5907.95, time=0-00:27:00)   
   Epoch 6.0841: train_loss/word=1.305 (words=49632, words/sec=5874.46, time=0-00:27:02)   
   Epoch 6.1118: train_loss/word=1.391 (words=68512, words/sec=5668.07, time=0-00:27:06)   
   Epoch 6.1404: train_loss/word=1.355 (words=83936, words/sec=5913.76, time=0-00:27:08)   
   Epoch 6.1681: train_loss/word=1.349 (words=100416, words/sec=5852.07, time=0-00:27:11)   
   Epoch 6.1958: train_loss/word=1.316 (words=115328, words/sec=5995.74, time=0-00:27:13)   
   Epoch 6.2236: train_loss/word=1.297 (words=127648, words/sec=5948.05, time=0-00:27:16)   
   Epoch 6.2522: train_loss/word=1.290 (words=142080, words/sec=6039.91, time=0-00:27:18)   
   Epoch 6.2799: train_loss/word=1.264 (words=154208, words/sec=6061.65, time=0-00:27:20)   
   Epoch 6.3076: train_loss/word=1.277 (words=173504, words/sec=6052.63, time=0-00:27:23)   
   Epoch 6.3353: train_loss/word=1.271 (words=189312, words/sec=6144.33, time=0-00:27:26)   
   Epoch 6.3640: train_loss/word=1.258 (words=201312, words/sec=6055.73, time=0-00:27:28)   
   Epoch 6.3917: train_loss/word=1.262 (words=217696, words/sec=5867.55, time=0-00:27:30)   
   Epoch 6.4194: train_loss/word=1.256 (words=231456, words/sec=6161.06, time=0-00:27:33)   
   Epoch 6.4471: train_loss/word=1.268 (words=247936, words/sec=5928.84, time=0-00:27:36)   
   Epoch 6.4757: train_loss/word=1.267 (words=262304, words/sec=5916.22, time=0-00:27:38)   
   Epoch 6.5035: train_loss/word=1.282 (words=281536, words/sec=5837.50, time=0-00:27:41)   
   Epoch 6.5312: train_loss/word=1.289 (words=300512, words/sec=5961.63, time=0-00:27:44)   
   Epoch 6.5589: train_loss/word=1.284 (words=313952, words/sec=5753.63, time=0-00:27:47)   
   Epoch 6.5875: train_loss/word=1.268 (words=326080, words/sec=5936.68, time=0-00:27:49)   
   Epoch 6.6152: train_loss/word=1.267 (words=341792, words/sec=5898.27, time=0-00:27:51)   
   Epoch 6.6430: train_loss/word=1.265 (words=355552, words/sec=5732.59, time=0-00:27:54)   
   Epoch 6.6707: train_loss/word=1.260 (words=368064, words/sec=5818.20, time=0-00:27:56)   
   Epoch 6.6993: train_loss/word=1.254 (words=379840, words/sec=5729.97, time=0-00:27:58)   
   Epoch 6.7270: train_loss/word=1.253 (words=394336, words/sec=6029.38, time=0-00:28:00)   
   Epoch 6.7550: train_loss/word=1.244 (words=405288, words/sec=5405.93, time=0-00:28:02)   
   Epoch 6.7827: train_loss/word=1.250 (words=421096, words/sec=6096.75, time=0-00:28:05)   
   Epoch 6.8104: train_loss/word=1.244 (words=434536, words/sec=6054.01, time=0-00:28:07)   
   Epoch 6.8390: train_loss/word=1.252 (words=451336, words/sec=5747.89, time=0-00:28:10)   
   Epoch 6.8668: train_loss/word=1.256 (words=468232, words/sec=5962.81, time=0-00:28:13)   
   Epoch 6.8945: train_loss/word=1.244 (words=477896, words/sec=6023.35, time=0-00:28:15)   
   Epoch 6.9222: train_loss/word=1.241 (words=488808, words/sec=5861.41, time=0-00:28:17)   
   Epoch 6.9508: train_loss/word=1.243 (words=503816, words/sec=5891.43, time=0-00:28:19)   
   Epoch 6.9785: train_loss/word=1.244 (words=518408, words/sec=5802.90, time=0-00:28:22)   
   Epoch 7.0000: train_loss/word=1.248 (words=531912, words/sec=5874.46, time=0-00:28:24)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 7.0000 dev [auxiliary] Loss: 3.128   
     Epoch 7.0000 dev BLEU4: 0.0538456879312, 0.278660/0.076844/0.029991/0.014700 (BP = 0.971418, ratio=0.97, hyp_len=16242, ref_len=16713) (words=29308, words/sec=206.91, time=0-00:30:46)   
     Epoch 7.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 7.0286: train_loss/word=0.681 (words=12576, words/sec=577.97, time=0-00:31:07)   
   Epoch 7.0563: train_loss/word=0.816 (words=26016, words/sec=5961.29, time=0-00:31:10)   
   Epoch 7.0841: train_loss/word=0.960 (words=41472, words/sec=5783.47, time=0-00:31:12)   
   Epoch 7.1118: train_loss/word=0.854 (words=51584, words/sec=6118.82, time=0-00:31:14)   
   Epoch 7.1404: train_loss/word=0.955 (words=68352, words/sec=5857.50, time=0-00:31:17)   
   Epoch 7.1681: train_loss/word=0.949 (words=81696, words/sec=5939.98, time=0-00:31:19)   
   Epoch 7.1958: train_loss/word=1.050 (words=100576, words/sec=5878.89, time=0-00:31:22)   
   Epoch 7.2236: train_loss/word=1.030 (words=116800, words/sec=6051.60, time=0-00:31:25)   
   Epoch 7.2522: train_loss/word=1.025 (words=135776, words/sec=6156.46, time=0-00:31:28)   
   Epoch 7.2799: train_loss/word=1.012 (words=149088, words/sec=5971.39, time=0-00:31:30)   
   Epoch 7.3076: train_loss/word=1.046 (words=164384, words/sec=5611.93, time=0-00:31:33)   
   Epoch 7.3353: train_loss/word=1.033 (words=175840, words/sec=5735.03, time=0-00:31:35)   
   Epoch 7.3640: train_loss/word=1.029 (words=188512, words/sec=5721.92, time=0-00:31:37)   
   Epoch 7.3917: train_loss/word=1.024 (words=201984, words/sec=5999.58, time=0-00:31:39)   
   Epoch 7.4194: train_loss/word=1.019 (words=215552, words/sec=6038.51, time=0-00:31:42)   
   Epoch 7.4471: train_loss/word=1.029 (words=232544, words/sec=5853.51, time=0-00:31:45)   
   Epoch 7.4757: train_loss/word=1.029 (words=247648, words/sec=5915.83, time=0-00:31:47)   
   Epoch 7.5035: train_loss/word=1.021 (words=259616, words/sec=6091.61, time=0-00:31:49)   
   Epoch 7.5312: train_loss/word=1.036 (words=276800, words/sec=6135.21, time=0-00:31:52)   
   Epoch 7.5589: train_loss/word=1.028 (words=288992, words/sec=6147.82, time=0-00:31:54)   
   Epoch 7.5875: train_loss/word=1.031 (words=304352, words/sec=5985.44, time=0-00:31:56)   
   Epoch 7.6152: train_loss/word=1.045 (words=320128, words/sec=5965.58, time=0-00:31:59)   
   Epoch 7.6430: train_loss/word=1.040 (words=331936, words/sec=6003.38, time=0-00:32:01)   
   Epoch 7.6707: train_loss/word=1.039 (words=345728, words/sec=5972.87, time=0-00:32:03)   
   Epoch 7.6993: train_loss/word=1.038 (words=359200, words/sec=5872.73, time=0-00:32:06)   
   Epoch 7.7270: train_loss/word=1.039 (words=372544, words/sec=5871.83, time=0-00:32:08)   
   Epoch 7.7547: train_loss/word=1.043 (words=388672, words/sec=5915.98, time=0-00:32:11)   
   Epoch 7.7825: train_loss/word=1.043 (words=404512, words/sec=6020.75, time=0-00:32:13)   
   Epoch 7.8111: train_loss/word=1.052 (words=421152, words/sec=5859.76, time=0-00:32:16)   
   Epoch 7.8388: train_loss/word=1.064 (words=437088, words/sec=5629.80, time=0-00:32:19)   
   Epoch 7.8665: train_loss/word=1.067 (words=451232, words/sec=5677.95, time=0-00:32:21)   
   Epoch 7.8942: train_loss/word=1.068 (words=467360, words/sec=5998.30, time=0-00:32:24)   
   Epoch 7.9222: train_loss/word=1.078 (words=487432, words/sec=5591.66, time=0-00:32:28)   
   Epoch 7.9508: train_loss/word=1.078 (words=502056, words/sec=6094.15, time=0-00:32:30)   
   Epoch 7.9785: train_loss/word=1.077 (words=515240, words/sec=5957.26, time=0-00:32:32)   
   Epoch 8.0000: train_loss/word=1.091 (words=531912, words/sec=5809.04, time=0-00:32:35)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 8.0000 dev [auxiliary] Loss: 3.103   
     Epoch 8.0000 dev BLEU4: 0.0528486949608, 0.279194/0.078877/0.028889/0.013495 (BP = 0.976329, ratio=0.98, hyp_len=16322, ref_len=16713) (words=29308, words/sec=202.75, time=0-00:35:00)   
   Epoch 8.0286: train_loss/word=0.498 (words=10624, words/sec=6117.56, time=0-00:35:01)   
   Epoch 8.0563: train_loss/word=0.799 (words=27424, words/sec=6208.13, time=0-00:35:04)   
   Epoch 8.0841: train_loss/word=0.894 (words=42880, words/sec=6067.25, time=0-00:35:07)   
   Epoch 8.1118: train_loss/word=0.884 (words=58880, words/sec=6271.07, time=0-00:35:09)   
   Epoch 8.1404: train_loss/word=0.945 (words=79360, words/sec=6103.29, time=0-00:35:13)   
   Epoch 8.1681: train_loss/word=0.984 (words=94112, words/sec=5798.25, time=0-00:35:15)   
   Epoch 8.1958: train_loss/word=0.961 (words=106624, words/sec=6183.63, time=0-00:35:17)   
   Epoch 8.2238: train_loss/word=0.948 (words=121736, words/sec=5775.05, time=0-00:35:20)   
   Epoch 8.2515: train_loss/word=0.917 (words=134760, words/sec=6359.33, time=0-00:35:22)   
   Epoch 8.2801: train_loss/word=0.923 (words=150184, words/sec=6085.98, time=0-00:35:24)   
   Epoch 8.3079: train_loss/word=0.925 (words=168168, words/sec=6290.35, time=0-00:35:27)   
   Epoch 8.3356: train_loss/word=0.901 (words=180456, words/sec=6296.36, time=0-00:35:29)   
   Epoch 8.3633: train_loss/word=0.918 (words=198792, words/sec=6092.13, time=0-00:35:32)   
   Epoch 8.3919: train_loss/word=0.953 (words=221160, words/sec=6078.12, time=0-00:35:36)   
   Epoch 8.4196: train_loss/word=0.984 (words=241736, words/sec=6209.03, time=0-00:35:39)   
   Epoch 8.4474: train_loss/word=0.987 (words=256872, words/sec=6358.47, time=0-00:35:42)   
   Epoch 8.4751: train_loss/word=0.994 (words=272232, words/sec=6173.40, time=0-00:35:44)   
   Epoch 8.5037: train_loss/word=0.977 (words=284360, words/sec=6655.88, time=0-00:35:46)   
   Epoch 8.5314: train_loss/word=0.976 (words=299432, words/sec=6642.66, time=0-00:35:48)   
   Epoch 8.5591: train_loss/word=0.963 (words=309608, words/sec=6670.97, time=0-00:35:50)   
   Epoch 8.5869: train_loss/word=0.949 (words=319688, words/sec=6593.27, time=0-00:35:51)   
   Epoch 8.6155: train_loss/word=0.951 (words=336488, words/sec=6617.19, time=0-00:35:54)   
   Epoch 8.6432: train_loss/word=0.959 (words=353896, words/sec=6478.49, time=0-00:35:56)   
   Epoch 8.6709: train_loss/word=0.973 (words=372072, words/sec=6382.51, time=0-00:35:59)   
   Epoch 8.6986: train_loss/word=0.977 (words=387272, words/sec=6539.66, time=0-00:36:02)   
   Epoch 8.7273: train_loss/word=0.965 (words=397608, words/sec=6671.71, time=0-00:36:03)   
   Epoch 8.7550: train_loss/word=0.959 (words=409992, words/sec=6529.28, time=0-00:36:05)   
   Epoch 8.7827: train_loss/word=0.954 (words=422952, words/sec=6772.39, time=0-00:36:07)   
   Epoch 8.8104: train_loss/word=0.948 (words=434440, words/sec=6693.25, time=0-00:36:09)   
   Epoch 8.8390: train_loss/word=0.943 (words=447080, words/sec=6677.12, time=0-00:36:11)   
   Epoch 8.8668: train_loss/word=0.940 (words=458952, words/sec=6530.41, time=0-00:36:12)   
   Epoch 8.8945: train_loss/word=0.941 (words=474184, words/sec=6498.37, time=0-00:36:15)   
   Epoch 8.9222: train_loss/word=0.942 (words=489672, words/sec=6609.45, time=0-00:36:17)   
   Epoch 8.9508: train_loss/word=0.943 (words=503176, words/sec=6545.12, time=0-00:36:19)   
   Epoch 8.9785: train_loss/word=0.951 (words=520008, words/sec=6584.34, time=0-00:36:22)   
   Epoch 9.0000: train_loss/word=0.952 (words=531912, words/sec=6725.59, time=0-00:36:23)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 9.0000 dev [auxiliary] Loss: 3.180   
     Epoch 9.0000 dev BLEU4: 0.0554554759093, 0.280522/0.077525/0.030532/0.016027 (BP = 0.970925, ratio=0.97, hyp_len=16234, ref_len=16713) (words=29308, words/sec=307.03, time=0-00:37:59)   
     Epoch 9.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 9.0286: train_loss/word=0.930 (words=17344, words/sec=1170.47, time=0-00:38:14)   
   Epoch 9.0563: train_loss/word=0.757 (words=29824, words/sec=6733.18, time=0-00:38:16)   
   Epoch 9.0841: train_loss/word=0.769 (words=44960, words/sec=6599.46, time=0-00:38:18)   
   Epoch 9.1118: train_loss/word=0.794 (words=61504, words/sec=6506.96, time=0-00:38:20)   
   Epoch 9.1404: train_loss/word=0.738 (words=73440, words/sec=6713.19, time=0-00:38:22)   
   Epoch 9.1681: train_loss/word=0.707 (words=84896, words/sec=6794.45, time=0-00:38:24)   
   Epoch 9.1958: train_loss/word=0.744 (words=100512, words/sec=6248.11, time=0-00:38:26)   
   Epoch 9.2236: train_loss/word=0.724 (words=112384, words/sec=6751.41, time=0-00:38:28)   
   Epoch 9.2522: train_loss/word=0.756 (words=129504, words/sec=6530.07, time=0-00:38:31)   
   Epoch 9.2799: train_loss/word=0.768 (words=146080, words/sec=6548.77, time=0-00:38:33)   
   Epoch 9.3076: train_loss/word=0.786 (words=162080, words/sec=6424.47, time=0-00:38:36)   
   Epoch 9.3353: train_loss/word=0.771 (words=172640, words/sec=6690.75, time=0-00:38:37)   
   Epoch 9.3640: train_loss/word=0.764 (words=187392, words/sec=6707.61, time=0-00:38:40)   
   Epoch 9.3917: train_loss/word=0.767 (words=200192, words/sec=6438.67, time=0-00:38:42)   
   Epoch 9.4194: train_loss/word=0.764 (words=213408, words/sec=6594.48, time=0-00:38:44)   
   Epoch 9.4471: train_loss/word=0.760 (words=227584, words/sec=6691.85, time=0-00:38:46)   
   Epoch 9.4757: train_loss/word=0.772 (words=244672, words/sec=6523.93, time=0-00:38:48)   
   Epoch 9.5035: train_loss/word=0.787 (words=262176, words/sec=6466.92, time=0-00:38:51)   
   Epoch 9.5312: train_loss/word=0.807 (words=279392, words/sec=6369.29, time=0-00:38:54)   
   Epoch 9.5589: train_loss/word=0.791 (words=291424, words/sec=6978.91, time=0-00:38:55)   
   Epoch 9.5875: train_loss/word=0.803 (words=307392, words/sec=6402.93, time=0-00:38:58)   
   Epoch 9.6152: train_loss/word=0.817 (words=324576, words/sec=6385.63, time=0-00:39:01)   
   Epoch 9.6430: train_loss/word=0.820 (words=339936, words/sec=6550.30, time=0-00:39:03)   
   Epoch 9.6707: train_loss/word=0.823 (words=354848, words/sec=6386.09, time=0-00:39:05)   
   Epoch 9.6993: train_loss/word=0.821 (words=367488, words/sec=6503.01, time=0-00:39:07)   
   Epoch 9.7270: train_loss/word=0.812 (words=378592, words/sec=6745.52, time=0-00:39:09)   
   Epoch 9.7547: train_loss/word=0.819 (words=394080, words/sec=6408.53, time=0-00:39:11)   
   Epoch 9.7825: train_loss/word=0.811 (words=406688, words/sec=6672.21, time=0-00:39:13)   
   Epoch 9.8111: train_loss/word=0.827 (words=427840, words/sec=6409.33, time=0-00:39:16)   
   Epoch 9.8390: train_loss/word=0.846 (words=446408, words/sec=5946.09, time=0-00:39:20)   
   Epoch 9.8668: train_loss/word=0.841 (words=461096, words/sec=6762.45, time=0-00:39:22)   
   Epoch 9.8945: train_loss/word=0.835 (words=475624, words/sec=6764.18, time=0-00:39:24)   
   Epoch 9.9222: train_loss/word=0.843 (words=493704, words/sec=6507.41, time=0-00:39:27)   
   Epoch 9.9508: train_loss/word=0.841 (words=507688, words/sec=6748.09, time=0-00:39:29)   
   Epoch 9.9785: train_loss/word=0.844 (words=522056, words/sec=6285.93, time=0-00:39:31)   
   Epoch 10.0000: train_loss/word=0.839 (words=531912, words/sec=6919.66, time=0-00:39:32)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 10.0000 dev [auxiliary] Loss: 3.218   
     Epoch 10.0000 dev BLEU4: 0.05719531831, 0.291498/0.080773/0.030403/0.014949 (BP = 1.000000, ratio=1.00, hyp_len=16796, ref_len=16713) (words=29308, words/sec=304.39, time=0-00:41:09)   
     Epoch 10.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 10.0286: train_loss/word=0.707 (words=14208, words/sec=514.24, time=0-00:41:36)   
   Epoch 10.0563: train_loss/word=0.510 (words=24224, words/sec=6832.87, time=0-00:41:38)   
   Epoch 10.0841: train_loss/word=0.670 (words=43488, words/sec=6315.50, time=0-00:41:41)   
   Epoch 10.1118: train_loss/word=0.635 (words=57472, words/sec=6764.00, time=0-00:41:43)   
   Epoch 10.1404: train_loss/word=0.678 (words=71904, words/sec=6434.20, time=0-00:41:45)   
   Epoch 10.1681: train_loss/word=0.714 (words=91264, words/sec=6636.40, time=0-00:41:48)   
   Epoch 10.1958: train_loss/word=0.732 (words=107872, words/sec=6497.15, time=0-00:41:51)   
   Epoch 10.2236: train_loss/word=0.753 (words=124768, words/sec=6428.72, time=0-00:41:53)   
   Epoch 10.2522: train_loss/word=0.728 (words=138368, words/sec=6700.45, time=0-00:41:55)   
   Epoch 10.2799: train_loss/word=0.740 (words=156736, words/sec=6592.97, time=0-00:41:58)   
   Epoch 10.3076: train_loss/word=0.721 (words=169824, words/sec=6787.64, time=0-00:42:00)   
   Epoch 10.3353: train_loss/word=0.715 (words=181312, words/sec=6459.62, time=0-00:42:02)   
   Epoch 10.3640: train_loss/word=0.714 (words=196256, words/sec=6493.48, time=0-00:42:04)   
   Epoch 10.3917: train_loss/word=0.702 (words=210112, words/sec=6707.44, time=0-00:42:06)   
   Epoch 10.4194: train_loss/word=0.730 (words=228512, words/sec=6340.98, time=0-00:42:09)   
   Epoch 10.4471: train_loss/word=0.726 (words=241824, words/sec=6596.28, time=0-00:42:11)   
   Epoch 10.4757: train_loss/word=0.737 (words=260224, words/sec=6399.30, time=0-00:42:14)   
   Epoch 10.5035: train_loss/word=0.739 (words=276896, words/sec=6569.04, time=0-00:42:17)   
   Epoch 10.5312: train_loss/word=0.747 (words=294592, words/sec=6484.73, time=0-00:42:19)   
   Epoch 10.5589: train_loss/word=0.737 (words=305568, words/sec=6649.64, time=0-00:42:21)   
   Epoch 10.5875: train_loss/word=0.729 (words=318336, words/sec=6724.13, time=0-00:42:23)   
   Epoch 10.6152: train_loss/word=0.725 (words=330688, words/sec=6583.76, time=0-00:42:25)   
   Epoch 10.6430: train_loss/word=0.734 (words=347680, words/sec=6376.20, time=0-00:42:27)   
   Epoch 10.6707: train_loss/word=0.751 (words=365344, words/sec=6257.29, time=0-00:42:30)   
   Epoch 10.6993: train_loss/word=0.753 (words=378592, words/sec=6329.13, time=0-00:42:32)   
   Epoch 10.7270: train_loss/word=0.745 (words=390464, words/sec=6766.84, time=0-00:42:34)   
   Epoch 10.7550: train_loss/word=0.746 (words=405096, words/sec=6039.23, time=0-00:42:36)   
   Epoch 10.7827: train_loss/word=0.748 (words=419688, words/sec=6467.16, time=0-00:42:39)   
   Epoch 10.8104: train_loss/word=0.739 (words=430696, words/sec=6748.61, time=0-00:42:40)   
   Epoch 10.8390: train_loss/word=0.741 (words=447240, words/sec=6606.98, time=0-00:42:43)   
   Epoch 10.8668: train_loss/word=0.733 (words=459688, words/sec=6918.21, time=0-00:42:45)   
   Epoch 10.8945: train_loss/word=0.731 (words=474696, words/sec=6648.22, time=0-00:42:47)   
   Epoch 10.9222: train_loss/word=0.731 (words=489064, words/sec=6614.14, time=0-00:42:49)   
   Epoch 10.9508: train_loss/word=0.733 (words=503272, words/sec=6550.44, time=0-00:42:51)   
   Epoch 10.9785: train_loss/word=0.741 (words=519432, words/sec=6428.92, time=0-00:42:54)   
   Epoch 11.0000: train_loss/word=0.739 (words=531912, words/sec=6737.45, time=0-00:42:56)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 11.0000 dev [auxiliary] Loss: 3.233   
     Epoch 11.0000 dev BLEU4: 0.0612202952168, 0.307702/0.093347/0.037907/0.018629 (BP = 0.912239, ratio=0.92, hyp_len=15307, ref_len=16713) (words=29308, words/sec=336.07, time=0-00:44:23)   
     Epoch 11.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 11.0286: train_loss/word=0.527 (words=15392, words/sec=1054.09, time=0-00:44:37)   
   Epoch 11.0563: train_loss/word=0.564 (words=31584, words/sec=6571.39, time=0-00:44:40)   
   Epoch 11.0841: train_loss/word=0.623 (words=50624, words/sec=6434.04, time=0-00:44:43)   
   Epoch 11.1118: train_loss/word=0.558 (words=61216, words/sec=6738.24, time=0-00:44:44)   
   Epoch 11.1404: train_loss/word=0.592 (words=77952, words/sec=6515.39, time=0-00:44:47)   
   Epoch 11.1681: train_loss/word=0.587 (words=90080, words/sec=6439.82, time=0-00:44:49)   
   Epoch 11.1958: train_loss/word=0.608 (words=104992, words/sec=6324.46, time=0-00:44:51)   
   Epoch 11.2236: train_loss/word=0.608 (words=118592, words/sec=6548.26, time=0-00:44:53)   
   Epoch 11.2522: train_loss/word=0.611 (words=136640, words/sec=6509.84, time=0-00:44:56)   
   Epoch 11.2799: train_loss/word=0.608 (words=149632, words/sec=6511.02, time=0-00:44:58)   
   Epoch 11.3076: train_loss/word=0.623 (words=168800, words/sec=6541.72, time=0-00:45:01)   
   Epoch 11.3353: train_loss/word=0.620 (words=183008, words/sec=6607.71, time=0-00:45:03)   
   Epoch 11.3640: train_loss/word=0.615 (words=195232, words/sec=6663.61, time=0-00:45:05)   
   Epoch 11.3917: train_loss/word=0.632 (words=209280, words/sec=6109.59, time=0-00:45:07)   
   Epoch 11.4194: train_loss/word=0.621 (words=220512, words/sec=6569.65, time=0-00:45:09)   
   Epoch 11.4471: train_loss/word=0.637 (words=237120, words/sec=6314.98, time=0-00:45:12)   
   Epoch 11.4757: train_loss/word=0.643 (words=253024, words/sec=6432.92, time=0-00:45:14)   
   Epoch 11.5035: train_loss/word=0.647 (words=267616, words/sec=6620.67, time=0-00:45:16)   
   Epoch 11.5314: train_loss/word=0.644 (words=281960, words/sec=6076.61, time=0-00:45:19)   
   Epoch 11.5591: train_loss/word=0.647 (words=297768, words/sec=6460.81, time=0-00:45:21)   
   Epoch 11.5869: train_loss/word=0.657 (words=316072, words/sec=6387.81, time=0-00:45:24)   
   Epoch 11.6155: train_loss/word=0.652 (words=332680, words/sec=6640.96, time=0-00:45:26)   
   Epoch 11.6432: train_loss/word=0.655 (words=346472, words/sec=6459.64, time=0-00:45:29)   
   Epoch 11.6709: train_loss/word=0.662 (words=362408, words/sec=6428.47, time=0-00:45:31)   
   Epoch 11.6986: train_loss/word=0.661 (words=376136, words/sec=6530.66, time=0-00:45:33)   
   Epoch 11.7273: train_loss/word=0.660 (words=391848, words/sec=6436.07, time=0-00:45:36)   
   Epoch 11.7550: train_loss/word=0.654 (words=405192, words/sec=6576.58, time=0-00:45:38)   
   Epoch 11.7827: train_loss/word=0.647 (words=415976, words/sec=6471.10, time=0-00:45:39)   
   Epoch 11.8104: train_loss/word=0.644 (words=429064, words/sec=6583.80, time=0-00:45:41)   
   Epoch 11.8390: train_loss/word=0.643 (words=445032, words/sec=6713.25, time=0-00:45:44)   
   Epoch 11.8668: train_loss/word=0.646 (words=459432, words/sec=6510.73, time=0-00:45:46)   
   Epoch 11.8945: train_loss/word=0.646 (words=474408, words/sec=6544.77, time=0-00:45:48)   
   Epoch 11.9222: train_loss/word=0.646 (words=488488, words/sec=6503.44, time=0-00:45:50)   
   Epoch 11.9508: train_loss/word=0.652 (words=506056, words/sec=6371.39, time=0-00:45:53)   
   Epoch 11.9785: train_loss/word=0.657 (words=522568, words/sec=6348.88, time=0-00:45:56)   
   Epoch 12.0000: train_loss/word=0.655 (words=531912, words/sec=6591.77, time=0-00:45:57)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 12.0000 dev [auxiliary] Loss: 3.275   
     Epoch 12.0000 dev BLEU4: 0.0599310424996, 0.296595/0.085724/0.034835/0.017933 (BP = 0.949336, ratio=0.95, hyp_len=15887, ref_len=16713) (words=29308, words/sec=320.04, time=0-00:47:29)   
   Epoch 12.0286: train_loss/word=0.246 (words=11392, words/sec=6573.13, time=0-00:47:30)   
   Epoch 12.0566: train_loss/word=0.552 (words=30440, words/sec=5977.47, time=0-00:47:34)   
   Epoch 12.0843: train_loss/word=0.478 (words=42088, words/sec=6648.57, time=0-00:47:35)   
   Epoch 12.1120: train_loss/word=0.519 (words=57416, words/sec=6428.57, time=0-00:47:38)   
   Epoch 12.1398: train_loss/word=0.483 (words=71240, words/sec=6895.68, time=0-00:47:40)   
   Epoch 12.1684: train_loss/word=0.467 (words=83368, words/sec=6591.23, time=0-00:47:42)   
   Epoch 12.1961: train_loss/word=0.458 (words=93960, words/sec=6506.24, time=0-00:47:43)   
   Epoch 12.2238: train_loss/word=0.505 (words=111464, words/sec=6415.46, time=0-00:47:46)   
   Epoch 12.2515: train_loss/word=0.526 (words=129000, words/sec=6485.11, time=0-00:47:49)   
   Epoch 12.2801: train_loss/word=0.525 (words=145032, words/sec=6673.05, time=0-00:47:51)   
   Epoch 12.3079: train_loss/word=0.524 (words=159944, words/sec=6509.71, time=0-00:47:53)   
   Epoch 12.3356: train_loss/word=0.557 (words=177416, words/sec=6146.78, time=0-00:47:56)   
   Epoch 12.3633: train_loss/word=0.558 (words=193256, words/sec=6597.58, time=0-00:47:59)   
   Epoch 12.3919: train_loss/word=0.552 (words=208360, words/sec=6516.02, time=0-00:48:01)   
   Epoch 12.4196: train_loss/word=0.557 (words=220584, words/sec=6434.91, time=0-00:48:03)   
   Epoch 12.4474: train_loss/word=0.572 (words=240296, words/sec=6344.14, time=0-00:48:06)   
   Epoch 12.4751: train_loss/word=0.587 (words=257544, words/sec=6378.64, time=0-00:48:09)   
   Epoch 12.5037: train_loss/word=0.581 (words=273288, words/sec=6797.16, time=0-00:48:11)   
   Epoch 12.5314: train_loss/word=0.575 (words=287048, words/sec=6706.78, time=0-00:48:13)   
   Epoch 12.5591: train_loss/word=0.572 (words=300104, words/sec=6583.15, time=0-00:48:15)   
   Epoch 12.5869: train_loss/word=0.568 (words=314952, words/sec=6792.88, time=0-00:48:17)   
   Epoch 12.6155: train_loss/word=0.577 (words=331592, words/sec=6445.30, time=0-00:48:20)   
   Epoch 12.6432: train_loss/word=0.575 (words=344648, words/sec=6743.25, time=0-00:48:22)   
   Epoch 12.6709: train_loss/word=0.576 (words=359240, words/sec=6560.27, time=0-00:48:24)   
   Epoch 12.6986: train_loss/word=0.591 (words=378472, words/sec=6415.75, time=0-00:48:27)   
   Epoch 12.7273: train_loss/word=0.586 (words=391880, words/sec=6645.20, time=0-00:48:29)   
   Epoch 12.7550: train_loss/word=0.586 (words=403368, words/sec=6512.04, time=0-00:48:31)   
   Epoch 12.7827: train_loss/word=0.584 (words=416936, words/sec=6479.99, time=0-00:48:33)   
   Epoch 12.8104: train_loss/word=0.582 (words=432520, words/sec=6624.37, time=0-00:48:35)   
   Epoch 12.8390: train_loss/word=0.582 (words=446952, words/sec=6511.44, time=0-00:48:37)   
   Epoch 12.8668: train_loss/word=0.574 (words=458056, words/sec=6835.19, time=0-00:48:39)   
   Epoch 12.8945: train_loss/word=0.570 (words=470088, words/sec=6792.17, time=0-00:48:41)   
   Epoch 12.9222: train_loss/word=0.569 (words=486696, words/sec=6675.67, time=0-00:48:43)   
   Epoch 12.9508: train_loss/word=0.571 (words=504680, words/sec=6614.76, time=0-00:48:46)   
   Epoch 12.9785: train_loss/word=0.577 (words=519944, words/sec=6433.58, time=0-00:48:48)   
   Epoch 13.0000: train_loss/word=0.581 (words=531912, words/sec=6386.30, time=0-00:48:50)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 13.0000 dev [auxiliary] Loss: 3.312   
     Epoch 13.0000 dev BLEU4: 0.0608117668443, 0.307267/0.088324/0.036035/0.018793 (BP = 0.928771, ratio=0.93, hyp_len=15563, ref_len=16713) (words=29308, words/sec=326.13, time=0-00:50:20)   
   Epoch 13.0286: train_loss/word=0.367 (words=14560, words/sec=6549.50, time=0-00:50:22)   
   Epoch 13.0563: train_loss/word=0.434 (words=28896, words/sec=6467.63, time=0-00:50:25)   
   Epoch 13.0841: train_loss/word=0.401 (words=42720, words/sec=6771.36, time=0-00:50:27)   
   Epoch 13.1118: train_loss/word=0.412 (words=57504, words/sec=6682.22, time=0-00:50:29)   
   Epoch 13.1404: train_loss/word=0.438 (words=76416, words/sec=6683.46, time=0-00:50:32)   
   Epoch 13.1681: train_loss/word=0.442 (words=92544, words/sec=6471.63, time=0-00:50:34)   
   Epoch 13.1958: train_loss/word=0.450 (words=107008, words/sec=6487.52, time=0-00:50:36)   
   Epoch 13.2236: train_loss/word=0.447 (words=120096, words/sec=6440.41, time=0-00:50:38)   
   Epoch 13.2515: train_loss/word=0.437 (words=134920, words/sec=6430.37, time=0-00:50:41)   
   Epoch 13.2801: train_loss/word=0.437 (words=146536, words/sec=6500.06, time=0-00:50:42)   
   Epoch 13.3079: train_loss/word=0.442 (words=161000, words/sec=6503.69, time=0-00:50:45)   
   Epoch 13.3356: train_loss/word=0.464 (words=180136, words/sec=6409.48, time=0-00:50:48)   
   Epoch 13.3633: train_loss/word=0.471 (words=195752, words/sec=6454.38, time=0-00:50:50)   
   Epoch 13.3919: train_loss/word=0.476 (words=213096, words/sec=6445.94, time=0-00:50:53)   
   Epoch 13.4196: train_loss/word=0.469 (words=223912, words/sec=6652.54, time=0-00:50:54)   
   Epoch 13.4474: train_loss/word=0.468 (words=239624, words/sec=6686.47, time=0-00:50:57)   
   Epoch 13.4751: train_loss/word=0.473 (words=254216, words/sec=6475.73, time=0-00:50:59)   
   Epoch 13.5037: train_loss/word=0.473 (words=265704, words/sec=6525.02, time=0-00:51:01)   
   Epoch 13.5314: train_loss/word=0.478 (words=281128, words/sec=6447.93, time=0-00:51:03)   
   Epoch 13.5591: train_loss/word=0.491 (words=297864, words/sec=6198.05, time=0-00:51:06)   
   Epoch 13.5869: train_loss/word=0.483 (words=309864, words/sec=6792.49, time=0-00:51:08)   
   Epoch 13.6155: train_loss/word=0.485 (words=324584, words/sec=6533.48, time=0-00:51:10)   
   Epoch 13.6432: train_loss/word=0.493 (words=342216, words/sec=6456.36, time=0-00:51:13)   
   Epoch 13.6709: train_loss/word=0.488 (words=353480, words/sec=6850.07, time=0-00:51:14)   
   Epoch 13.6986: train_loss/word=0.487 (words=365256, words/sec=6525.22, time=0-00:51:16)   
   Epoch 13.7273: train_loss/word=0.498 (words=381704, words/sec=6230.90, time=0-00:51:19)   
   Epoch 13.7550: train_loss/word=0.501 (words=395944, words/sec=6374.27, time=0-00:51:21)   
   Epoch 13.7827: train_loss/word=0.509 (words=415432, words/sec=6464.48, time=0-00:51:24)   
   Epoch 13.8104: train_loss/word=0.515 (words=434376, words/sec=6461.42, time=0-00:51:27)   
   Epoch 13.8390: train_loss/word=0.514 (words=447272, words/sec=6520.14, time=0-00:51:29)   
   Epoch 13.8668: train_loss/word=0.521 (words=464616, words/sec=6384.29, time=0-00:51:32)   
   Epoch 13.8945: train_loss/word=0.520 (words=482024, words/sec=6729.41, time=0-00:51:34)   
   Epoch 13.9222: train_loss/word=0.518 (words=495240, words/sec=6651.82, time=0-00:51:36)   
   Epoch 13.9508: train_loss/word=0.520 (words=510312, words/sec=6634.64, time=0-00:51:38)   
   Epoch 13.9785: train_loss/word=0.520 (words=523560, words/sec=6496.73, time=0-00:51:40)   
   Epoch 14.0000: train_loss/word=0.517 (words=531912, words/sec=6581.89, time=0-00:51:42)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 14.0000 dev [auxiliary] Loss: 3.434   
     Epoch 14.0000 dev BLEU4: 0.0661852546382, 0.305394/0.090811/0.037661/0.020164 (BP = 0.977003, ratio=0.98, hyp_len=16333, ref_len=16713) (words=29308, words/sec=314.44, time=0-00:53:15)   
     Epoch 14.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 14.0286: train_loss/word=0.414 (words=12640, words/sec=460.08, time=0-00:53:42)   
   Epoch 14.0563: train_loss/word=0.375 (words=24928, words/sec=6644.34, time=0-00:53:44)   
   Epoch 14.0841: train_loss/word=0.495 (words=43616, words/sec=6270.28, time=0-00:53:47)   
   Epoch 14.1118: train_loss/word=0.487 (words=59168, words/sec=6604.70, time=0-00:53:50)   
   Epoch 14.1404: train_loss/word=0.513 (words=78144, words/sec=6424.65, time=0-00:53:53)   
   Epoch 14.1681: train_loss/word=0.491 (words=94912, words/sec=6678.35, time=0-00:53:55)   
   Epoch 14.1961: train_loss/word=0.478 (words=108456, words/sec=6117.83, time=0-00:53:57)   
   Epoch 14.2238: train_loss/word=0.453 (words=118216, words/sec=6797.59, time=0-00:53:59)   
   Epoch 14.2515: train_loss/word=0.445 (words=129576, words/sec=6508.95, time=0-00:54:00)   
   Epoch 14.2801: train_loss/word=0.447 (words=143944, words/sec=6569.70, time=0-00:54:03)   
   Epoch 14.3079: train_loss/word=0.455 (words=159656, words/sec=6414.59, time=0-00:54:05)   
   Epoch 14.3356: train_loss/word=0.460 (words=176328, words/sec=6414.16, time=0-00:54:08)   
   Epoch 14.3633: train_loss/word=0.468 (words=193928, words/sec=6534.97, time=0-00:54:10)   
   Epoch 14.3919: train_loss/word=0.472 (words=209448, words/sec=6543.16, time=0-00:54:13)   
   Epoch 14.4196: train_loss/word=0.469 (words=225320, words/sec=6404.84, time=0-00:54:15)   
   Epoch 14.4474: train_loss/word=0.485 (words=243400, words/sec=6337.48, time=0-00:54:18)   
   Epoch 14.4751: train_loss/word=0.486 (words=259048, words/sec=6399.80, time=0-00:54:21)   
   Epoch 14.5037: train_loss/word=0.480 (words=276808, words/sec=6735.05, time=0-00:54:23)   
   Epoch 14.5314: train_loss/word=0.475 (words=293160, words/sec=6720.50, time=0-00:54:26)   
   Epoch 14.5591: train_loss/word=0.471 (words=310856, words/sec=6712.64, time=0-00:54:28)   
   Epoch 14.5869: train_loss/word=0.475 (words=325832, words/sec=6328.02, time=0-00:54:31)   
   Epoch 14.6155: train_loss/word=0.476 (words=340328, words/sec=6422.72, time=0-00:54:33)   
   Epoch 14.6432: train_loss/word=0.471 (words=351944, words/sec=6615.09, time=0-00:54:35)   
   Epoch 14.6709: train_loss/word=0.468 (words=367080, words/sec=6553.03, time=0-00:54:37)   
   Epoch 14.6986: train_loss/word=0.470 (words=381192, words/sec=6416.20, time=0-00:54:39)   
   Epoch 14.7273: train_loss/word=0.463 (words=390440, words/sec=6842.12, time=0-00:54:40)   
   Epoch 14.7550: train_loss/word=0.460 (words=406664, words/sec=6642.99, time=0-00:54:43)   
   Epoch 14.7827: train_loss/word=0.457 (words=420936, words/sec=6639.08, time=0-00:54:45)   
   Epoch 14.8104: train_loss/word=0.451 (words=433704, words/sec=6795.25, time=0-00:54:47)   
   Epoch 14.8390: train_loss/word=0.453 (words=448552, words/sec=6434.69, time=0-00:54:49)   
   Epoch 14.8668: train_loss/word=0.452 (words=460104, words/sec=6534.66, time=0-00:54:51)   
   Epoch 14.8945: train_loss/word=0.450 (words=473000, words/sec=6483.98, time=0-00:54:53)   
   Epoch 14.9222: train_loss/word=0.455 (words=489960, words/sec=6498.88, time=0-00:54:56)   
   Epoch 14.9508: train_loss/word=0.452 (words=503368, words/sec=6617.69, time=0-00:54:58)   
   Epoch 14.9785: train_loss/word=0.456 (words=519304, words/sec=6408.68, time=0-00:55:00)   
   Epoch 15.0000: train_loss/word=0.458 (words=531912, words/sec=6361.80, time=0-00:55:02)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 15.0000 dev [auxiliary] Loss: 3.486   
     Epoch 15.0000 dev BLEU4: 0.0628485492736, 0.312797/0.096835/0.040392/0.020347 (BP = 0.889758, ratio=0.90, hyp_len=14965, ref_len=16713) (words=29308, words/sec=342.86, time=0-00:56:28)   
   Epoch 15.0286: train_loss/word=0.331 (words=15264, words/sec=6461.16, time=0-00:56:30)   
   Epoch 15.0563: train_loss/word=0.385 (words=33024, words/sec=6580.26, time=0-00:56:33)   
   Epoch 15.0841: train_loss/word=0.372 (words=48160, words/sec=6694.52, time=0-00:56:35)   
   Epoch 15.1118: train_loss/word=0.384 (words=62592, words/sec=6490.67, time=0-00:56:37)   
   Epoch 15.1404: train_loss/word=0.372 (words=80448, words/sec=6602.59, time=0-00:56:40)   
   Epoch 15.1681: train_loss/word=0.351 (words=93472, words/sec=6693.21, time=0-00:56:42)   
   Epoch 15.1958: train_loss/word=0.381 (words=108512, words/sec=6203.35, time=0-00:56:44)   
   Epoch 15.2236: train_loss/word=0.387 (words=122752, words/sec=6396.37, time=0-00:56:46)   
   Epoch 15.2515: train_loss/word=0.386 (words=139432, words/sec=6203.21, time=0-00:56:49)   
   Epoch 15.2801: train_loss/word=0.370 (words=149896, words/sec=6693.51, time=0-00:56:51)   
   Epoch 15.3079: train_loss/word=0.377 (words=164584, words/sec=6534.67, time=0-00:56:53)   
   Epoch 15.3356: train_loss/word=0.387 (words=182696, words/sec=6438.71, time=0-00:56:56)   
   Epoch 15.3633: train_loss/word=0.388 (words=196744, words/sec=6588.69, time=0-00:56:58)   
   Epoch 15.3919: train_loss/word=0.392 (words=214408, words/sec=6497.05, time=0-00:57:01)   
   Epoch 15.4196: train_loss/word=0.393 (words=228776, words/sec=6579.89, time=0-00:57:03)   
   Epoch 15.4474: train_loss/word=0.396 (words=245032, words/sec=6596.17, time=0-00:57:05)   
   Epoch 15.4751: train_loss/word=0.393 (words=262088, words/sec=6727.77, time=0-00:57:08)   
   Epoch 15.5037: train_loss/word=0.383 (words=270856, words/sec=6762.01, time=0-00:57:09)   
   Epoch 15.5314: train_loss/word=0.383 (words=283144, words/sec=6449.27, time=0-00:57:11)   
   Epoch 15.5591: train_loss/word=0.393 (words=299496, words/sec=6450.44, time=0-00:57:14)   
   Epoch 15.5869: train_loss/word=0.390 (words=313384, words/sec=6607.95, time=0-00:57:16)   
   Epoch 15.6155: train_loss/word=0.389 (words=328648, words/sec=6569.24, time=0-00:57:18)   
   Epoch 15.6432: train_loss/word=0.388 (words=343304, words/sec=6743.55, time=0-00:57:20)   
   Epoch 15.6709: train_loss/word=0.387 (words=357544, words/sec=6757.60, time=0-00:57:22)   
   Epoch 15.6986: train_loss/word=0.392 (words=375176, words/sec=6487.07, time=0-00:57:25)   
   Epoch 15.7273: train_loss/word=0.389 (words=388424, words/sec=6763.50, time=0-00:57:27)   
   Epoch 15.7550: train_loss/word=0.390 (words=403016, words/sec=6514.16, time=0-00:57:29)   
   Epoch 15.7827: train_loss/word=0.388 (words=418440, words/sec=6759.04, time=0-00:57:31)   
   Epoch 15.8104: train_loss/word=0.384 (words=430664, words/sec=6798.26, time=0-00:57:33)   
   Epoch 15.8390: train_loss/word=0.389 (words=448808, words/sec=6521.06, time=0-00:57:36)   
   Epoch 15.8668: train_loss/word=0.390 (words=460456, words/sec=6532.07, time=0-00:57:38)   
   Epoch 15.8945: train_loss/word=0.399 (words=476072, words/sec=6273.51, time=0-00:57:40)   
   Epoch 15.9222: train_loss/word=0.401 (words=490472, words/sec=6488.61, time=0-00:57:43)   
   Epoch 15.9508: train_loss/word=0.402 (words=502760, words/sec=6357.46, time=0-00:57:44)   
   Epoch 15.9785: train_loss/word=0.405 (words=517512, words/sec=6301.76, time=0-00:57:47)   
   Epoch 16.0000: train_loss/word=0.412 (words=531912, words/sec=6305.40, time=0-00:57:49)   
   initialized PolynomialNormalization({'apply_during_search': True})   
   /projects/tir2/users/xinyiw1/loreili/dev.piece.src   
   > Checkpoint   
     Epoch 16.0000 dev [auxiliary] Loss: 3.512   
     Epoch 16.0000 dev BLEU4: 0.0668957846575, 0.319664/0.096704/0.040956/0.020315 (BP = 0.939357, ratio=0.94, hyp_len=15729, ref_len=16713) (words=29308, words/sec=331.06, time=0-00:59:18)   
     Epoch 16.0000: best dev score, writing model to examples/output/oromo-seq.mod   
   Epoch 16.0286: train_loss/word=0.336 (words=15744, words/sec=720.18, time=0-00:59:39)   
   Epoch 16.0563: train_loss/word=0.393 (words=31840, words/sec=6155.85, time=0-00:59:42)   
   Epoch 16.0841: train_loss/word=0.396 (words=49920, words/sec=6411.74, time=0-00:59:45)   
   Epoch 16.1118: train_loss/word=0.357 (words=63744, words/sec=6741.67, time=0-00:59:47)   
   Epoch 16.1404: train_loss/word=0.337 (words=75520, words/sec=6759.84, time=0-00:59:49)   
   Epoch 16.1681: train_loss/word=0.353 (words=93600, words/sec=6346.72, time=0-00:59:52)   
   Epoch 16.1958: train_loss/word=0.349 (words=108736, words/sec=6714.26, time=0-00:59:54)   
   Epoch 16.2236: train_loss/word=0.351 (words=121632, words/sec=6359.64, time=0-00:59:56)   
   Epoch 16.2522: train_loss/word=0.339 (words=136032, words/sec=6693.24, time=0-00:59:58)   
   Epoch 16.2799: train_loss/word=0.352 (words=152448, words/sec=6381.19, time=0-01:00:01)   
slurmstepd: error: *** JOB 25301 ON compute-0-17 CANCELLED AT 2017-11-09T17:17:04 DUE TO TIME LIMIT ***
